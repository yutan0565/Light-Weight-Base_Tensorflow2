{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yutan0565/colab_git/blob/main/MobileNet_V3_Small_%EC%98%88%EC%8B%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HgXJWEEeK0D"
   },
   "source": [
    "## 기본 모델 형성\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WWaiDdX78kFi"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fO2RGXR2JRxq"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import tempfile\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
    "import tensorflow_model_optimization as tfmot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0ptbBJ19JRz_",
    "outputId": "62cd4cdc-a32f-4fea-e0ef-9eeda05daa8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(raw_train_x.shape)\\nprint(raw_test_x.shape)\\nprint(raw_train_y.shape)\\nprint(raw_test_y.shape)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "\"\"\"\n",
    "print(raw_train_x.shape)\n",
    "print(raw_test_x.shape)\n",
    "print(raw_train_y.shape)\n",
    "print(raw_test_y.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "Y3XsyJumvC4Z",
    "outputId": "5eade7af-bca5-49dc-d289-189e276c368f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(train_x.shape)\\nprint(valid_x.shape)\\nprint(test_x.shape)\\nprint(train_y.shape)\\nprint(valid_y.shape)\\nprint(test_y.shape)\\n\\ndef show_sample(i):\\n  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\\n  plt.imshow(raw_train_x[i])\\n  plt.show()\\n\\nfor i in [2, 10, 12, 14]:\\n  show_sample(i)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float을 넣을거면 0~1 사이 값으로 바꿔야함\n",
    "# integer 형태로 넣어보기\n",
    "train_x = raw_train_x[:45000].astype(np.float32)/255.0\n",
    "valid_x = raw_train_x[45000:].astype(np.float32)/255.0\n",
    "test_x = raw_test_x.astype(np.float32)/255.0\n",
    "\n",
    "\n",
    "train_y = raw_train_y[:45000]\n",
    "valid_y = raw_train_y[45000:]\n",
    "test_y = raw_test_y\n",
    "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(train_x.shape)\n",
    "print(valid_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_y.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "def show_sample(i):\n",
    "  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\n",
    "  plt.imshow(raw_train_x[i])\n",
    "  plt.show()\n",
    "\n",
    "for i in [2, 10, 12, 14]:\n",
    "  show_sample(i)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nLvUwGGvQ8w",
    "outputId": "82aa95f2-4a16-49cb-ca7f-798122bc737b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "MobilenetV3small (Functional (None, 1, 1, 1024)        1529968   \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 10)                3159050   \n",
      "=================================================================\n",
      "Total params: 4,689,018\n",
      "Trainable params: 4,676,906\n",
      "Non-trainable params: 12,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile = MobileNetV3Small(  #weights = 'imagenet',  #그냥 초기화 하는거면, 이거 지우기\n",
    "                            include_top = False,\n",
    "                            input_shape=(32,32,3)\n",
    "                            )\n",
    "\n",
    "# vgg conv 구조만 사용하고 마지막 FC layer는 다른거 사용\n",
    "\n",
    "fc_layer = keras.Sequential([\n",
    "                             layers.Flatten(),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(10, activation = \"sigmoid\")\n",
    "                             ])\n",
    "\n",
    "model = keras.Sequential([mobile,\n",
    "                          fc_layer\n",
    "                          ])\n",
    "model.summary()\n",
    "# mobile.summary()\n",
    "# fc_layer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NgPjo_LX7X6x"
   },
   "outputs": [],
   "source": [
    "# Callback 함수 지정 해주기\n",
    "early_stop = EarlyStopping(patience=20) \n",
    "mc = ModelCheckpoint(\"/check_point.h5\", save_best_only=True) \n",
    "reduce_lr  = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                               factor=0.5, \n",
    "                               patience=5\n",
    "                               ) \n",
    "csvlogger = CSVLogger(\"model_log.log\") \n",
    "\n",
    "# tensorboard 관련 \n",
    "def make_Tensorboard_dir(dir_name):\n",
    "  root_logdir = os.path.join(os.curdir, dir_name)\n",
    "  sub_dir_name = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  return os.path.join(root_logdir, sub_dir_name)\n",
    "\n",
    "dir_name = \"Learning_log\"\n",
    "TB_log_dir = make_Tensorboard_dir(dir_name)\n",
    "TensorB = TensorBoard(log_dir = TB_log_dir)\n",
    "\n",
    "\n",
    "#optimizaer  조정 해주기\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZ-LukhIvphi",
    "outputId": "656b43c1-135b-4314-8443-fb5a414d5345",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "352/352 [==============================] - 32s 68ms/step - loss: 1.8999 - accuracy: 0.3130 - val_loss: 3.0908 - val_accuracy: 0.0986\n",
      "Epoch 2/100\n",
      "352/352 [==============================] - 21s 60ms/step - loss: 1.4470 - accuracy: 0.4784 - val_loss: 3.4441 - val_accuracy: 0.0986\n",
      "Epoch 3/100\n",
      "352/352 [==============================] - 21s 59ms/step - loss: 1.2552 - accuracy: 0.5562 - val_loss: 4.3377 - val_accuracy: 0.0986\n",
      "Epoch 4/100\n",
      "264/352 [=====================>........] - ETA: 5s - loss: 1.1295 - accuracy: 0.5984"
     ]
    }
   ],
   "source": [
    "# optimizer, loss 함수를 정의하고,  학습 준비를 한다,  metrics 는 어떤 일이 발생하는지 보여줄 것들\n",
    "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "# 한번에 몇개의 데이터 학습하고 가중치 갱신할지 \n",
    "model.fit(train_x, train_y,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          batch_size=128,\n",
    "          #validation_split = 0.1\n",
    "          validation_data = (valid_x, valid_y),\n",
    "          callbacks = [early_stop, reduce_lr , csvlogger]\n",
    "          )\n",
    "\n",
    "# call back 참고 : https://deep-deep-deep.tistory.com/1 들어가면 여러 옵션들이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIGR4cUIFFFG",
    "outputId": "4e8efb31-7e7e-400c-f85a-67d2b59e3b88"
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_x, test_y)\n",
    "print(\"loss=\",loss)\n",
    "print(\"acc=\",acc)\n",
    "\n",
    "y_ = model.predict(test_x)\n",
    "predicted = np.argmax(y_, axis=1)\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "q73p7Ywkzv9i",
    "outputId": "bc0a2976-7118-43f2-992d-192770759025"
   },
   "outputs": [],
   "source": [
    "model.save(\"./saved_model/mobile_original.h5\")\n",
    "model.save(\"./saved_model/mobile_original_checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWaTjCHHeZJJ"
   },
   "source": [
    "## int_8 Quantization 진행\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kR1YvGr6TqB0"
   },
   "outputs": [],
   "source": [
    "# 구조까지 들어가 있는거\n",
    "model = tf.keras.models.load_model('./saved_model/mobile_original_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "K_pCuwiQSAec"
   },
   "outputs": [],
   "source": [
    "# input 에 대해서 변수 설정\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_x).batch(1).take(100):\n",
    "    yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mvxpgAD7SAvS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmpj_a86_sg\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmpj_a86_sg\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n",
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    }
   ],
   "source": [
    "# int 8 로 quantization 진행하기\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uLjaFd7wavtS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmpeq7ecdyx\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmpeq7ecdyx\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "# 그냥 파일 형태만 tflite로 변환 (float 형태임)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8xyG2LcUUJT9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZdR24DrHUfpg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2648104"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 저장 해주는 과정\n",
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"/tmp/mobile_tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the unquantized/float model:\n",
    "tflite_model_file = tflite_models_dir/\"mobile_model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = tflite_models_dir/\"mobiile_model_quant.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAK1WC33UfxT"
   },
   "outputs": [],
   "source": [
    "# tensorlffow lite 모델 실행 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "13myIyvtcyto"
   },
   "outputs": [],
   "source": [
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  global test_x\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = test_x[test_image_index]\n",
    "    test_label = test_y[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Lv1HJGcxcJR9"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(tflite_file, model_type):\n",
    "  global test_x\n",
    "  global test_y\n",
    "\n",
    "  test_image_indices = range(test_x.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_image_indices)\n",
    "\n",
    "  accuracy = (np.sum(test_y.reshape(-1)== predictions) * 100) / len(test_x)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bac0X0MIcJ-y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model accuracy is 57.3900% (Number of test samples=10000)\n",
      "Quantized model accuracy is 10.0000% (Number of test samples=10000)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(tflite_model_file, model_type=\"Float\")\n",
    "evaluate_model(tflite_model_quant_file, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wJ8BqBRecLa_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Change this to test a different image\n",
    "test_image_index = 1\n",
    "\n",
    "## Helper function to test the models on one image\n",
    "def test_model(tflite_file, test_image_index, model_type):\n",
    "  global test_labels\n",
    "\n",
    "  predictions = run_tflite_model(tflite_file, [test_image_index])\n",
    "\n",
    "  plt.imshow(test_x[test_image_index])\n",
    "  template = model_type + \" Model \\n True:{true}, Predicted:{predict}\"\n",
    "  _ = plt.title(template.format(true= str(test_y[test_image_index]), predict=str(predictions[0])))\n",
    "  plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "kgJlkK8kdnKT"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_model(tflite_model_file, test_image_index, model_type=\"Float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "XWXNXX5ydpG5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_model(tflite_model_quant_file, test_image_index, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm0ntodhlF8y"
   },
   "source": [
    "## Pruning 진행\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjlumF76nDzo"
   },
   "outputs": [],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_x, test_y, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tESxUKGaf5Q"
   },
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Dense, tfmot.sparsity.keras.PrunableLayer):\n",
    "\n",
    "  def get_prunable_weights(self):\n",
    "    # Prune bias also, though that usually harms model accuracy too much.\n",
    "    return [self.kernel, self.bias]\n",
    "\n",
    "# Use `prune_low_magnitude` to make the `MyDenseLayer` layer train with pruning.\n",
    "model_for_pruning = tf.keras.Sequential([\n",
    "  tfmot.sparsity.keras.prune_low_magnitude(MyDenseLayer(20, input_shape=input_shape)),\n",
    "  tf.keras.layers.Flatten()\n",
    "])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dET8FyEYnZdG"
   },
   "outputs": [],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_x.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4voFQPDRyuWG"
   },
   "outputs": [],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_x, train_,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lzpm4N3DyvEp"
   },
   "outputs": [],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_x, test_y, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_ZkuMoWywo6"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtnCY7h-y0Fd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRZDWu6V4A9w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTuWeu5d4BBs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bF_0FHG4BHX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctE1qnS24BO3"
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "%load_ext tensorboard\n",
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ")\n",
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()\n",
    "\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)\n",
    "\n",
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFMqKHpO4MR3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPny8C6A9oWM5wv/y4HdNQm",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1Et-iwTi6UUUc5F1_JvqO-_LjfL43QBV_",
   "name": "MobileNet_V3_Small_예시.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
