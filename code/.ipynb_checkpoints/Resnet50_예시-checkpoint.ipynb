{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yutan0565/colab_git/blob/main/code/MobileNet_V3_Small_%EC%98%88%EC%8B%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTOd0ahJOZsr"
   },
   "source": [
    "##기본 모델 형성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNI1wdG4N7yF",
    "outputId": "2080654c-6979-443e-9516-da8a3f2f40f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |█▍                              | 10 kB 20.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 20 kB 22.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 30 kB 27.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 40 kB 16.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 51 kB 14.5 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 61 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 71 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 81 kB 14.0 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 92 kB 15.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 102 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 112 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 122 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 133 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 143 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 153 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 163 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 174 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 184 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 194 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 204 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 215 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 225 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 235 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 237 kB 16.3 MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pZRQ2Jc4OCS1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "7R6Yikb4OCuf",
    "outputId": "c2fdef5f-6db2-40a4-c2c4-a76675e44fc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(raw_train_x.shape)\\nprint(raw_test_x.shape)\\nprint(raw_train_y.shape)\\nprint(raw_test_y.shape)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "\"\"\"\n",
    "print(raw_train_x.shape)\n",
    "print(raw_test_x.shape)\n",
    "print(raw_train_y.shape)\n",
    "print(raw_test_y.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6]\n",
      " [9]\n",
      " [9]\n",
      " ...\n",
      " [9]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "yuQ_qeDSODzw",
    "outputId": "13f56c8b-6d6b-4024-bf7f-68d821b8e578"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(train_x.shape)\\nprint(valid_x.shape)\\nprint(test_x.shape)\\nprint(train_y.shape)\\nprint(valid_y.shape)\\nprint(test_y.shape)\\n\\ndef show_sample(i):\\n  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\\n  plt.imshow(raw_train_x[i])\\n  plt.show()\\n\\nfor i in [2, 10, 12, 14]:\\n  show_sample(i)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float을 넣을거면 0~1 사이 값으로 바꿔야함\n",
    "# integer 형태로 넣어보기\n",
    "train_x = raw_train_x[:45000].astype(np.float32)/255.0\n",
    "valid_x = raw_train_x[45000:].astype(np.float32)/255.0\n",
    "test_x = raw_test_x.astype(np.float32)/255.0\n",
    "\n",
    "\n",
    "train_y = raw_train_y[:45000]\n",
    "valid_y = raw_train_y[45000:]\n",
    "test_y = raw_test_y\n",
    "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(train_x.shape)\n",
    "print(valid_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_y.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "def show_sample(i):\n",
    "  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\n",
    "  plt.imshow(raw_train_x[i])\n",
    "  plt.show()\n",
    "\n",
    "for i in [2, 10, 12, 14]:\n",
    "  show_sample(i)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wwn3NFrmOFeq",
    "outputId": "39e134ed-bbd7-4d3b-84b3-18c23da45a40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 10)                4207626   \n",
      "=================================================================\n",
      "Total params: 27,795,338\n",
      "Trainable params: 27,742,218\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNet50(  #weights = 'imagenet',  #그냥 초기화 하는거면, 이거 지우기\n",
    "                            include_top = False,\n",
    "                            input_shape=(32,32,3)\n",
    "                            )\n",
    "\n",
    "# vgg conv 구조만 사용하고 마지막 FC layer는 다른거 사용\n",
    "\n",
    "fc_layer = keras.Sequential([\n",
    "                             layers.Flatten(),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(10, activation = \"sigmoid\")\n",
    "                             ])\n",
    "\n",
    "model = keras.Sequential([resnet,\n",
    "                          fc_layer\n",
    "                          ])\n",
    "model.summary()\n",
    "# resnet.summary()\n",
    "# fc_layer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VuUFfKa1OIUa"
   },
   "outputs": [],
   "source": [
    "# Callback 함수 지정 해주기\n",
    "early_stop = EarlyStopping(patience=30) \n",
    "mc = ModelCheckpoint(\"./best_model/resnet_original_checkpoint\", \n",
    "                     save_best_only=True,\n",
    "                     monitor = 'val_loss',\n",
    "                     verbose = 1,\n",
    "                     mode = 'min') \n",
    "reduce_lr  = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                               factor=0.5, \n",
    "                               patience=5\n",
    "                               ) \n",
    "# tensorboard 관련 \n",
    "def make_Tensorboard_dir(dir_name):\n",
    "  root_logdir = os.path.join(os.curdir, dir_name)\n",
    "  sub_dir_name = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  return os.path.join(root_logdir, sub_dir_name)\n",
    "\n",
    "dir_name = \"Learning_log\"\n",
    "TB_log_dir = make_Tensorboard_dir(dir_name)\n",
    "TensorB = TensorBoard(log_dir = TB_log_dir)\n",
    "\n",
    "\n",
    "#optimizaer  조정 해주기\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3K9FF5gmOLH6",
    "outputId": "2f7c3f80-6d86-4397-f4c1-d892168f980c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 291s 197ms/step - loss: 1.1577 - accuracy: 0.5981 - val_loss: 0.7645 - val_accuracy: 0.7450\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76448, saving model to ./best_model\\resnet_original_checkpoint\n",
      "INFO:tensorflow:Assets written to: ./best_model\\resnet_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 274s 195ms/step - loss: 0.7190 - accuracy: 0.7561 - val_loss: 0.6270 - val_accuracy: 0.7858\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.76448 to 0.62705, saving model to ./best_model\\resnet_original_checkpoint\n",
      "INFO:tensorflow:Assets written to: ./best_model\\resnet_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 278s 198ms/step - loss: 0.5431 - accuracy: 0.8180 - val_loss: 0.6196 - val_accuracy: 0.7946\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62705 to 0.61959, saving model to ./best_model\\resnet_original_checkpoint\n",
      "INFO:tensorflow:Assets written to: ./best_model\\resnet_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 275s 196ms/step - loss: 0.4215 - accuracy: 0.8571 - val_loss: 0.5991 - val_accuracy: 0.8102\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61959 to 0.59911, saving model to ./best_model\\resnet_original_checkpoint\n",
      "INFO:tensorflow:Assets written to: ./best_model\\resnet_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 276s 196ms/step - loss: 0.3272 - accuracy: 0.8897 - val_loss: 0.6220 - val_accuracy: 0.8118\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.59911\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 270s 192ms/step - loss: 0.2560 - accuracy: 0.9156 - val_loss: 0.6347 - val_accuracy: 0.8118\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.59911\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 270s 192ms/step - loss: 0.2077 - accuracy: 0.9318 - val_loss: 0.7318 - val_accuracy: 0.8004\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.59911\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 270s 192ms/step - loss: 0.1743 - accuracy: 0.9422 - val_loss: 0.6992 - val_accuracy: 0.8172\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.59911\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 270s 192ms/step - loss: 0.1401 - accuracy: 0.9539 - val_loss: 0.7275 - val_accuracy: 0.8136\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.59911\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 270s 192ms/step - loss: 0.0647 - accuracy: 0.9784 - val_loss: 0.7472 - val_accuracy: 0.8358\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.59911\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 270s 192ms/step - loss: 0.0408 - accuracy: 0.9864 - val_loss: 0.8024 - val_accuracy: 0.8364\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.59911\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 270s 192ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 0.8773 - val_accuracy: 0.8294\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.59911\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 270s 192ms/step - loss: 0.0376 - accuracy: 0.9877 - val_loss: 0.8927 - val_accuracy: 0.8402\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.59911\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 270s 192ms/step - loss: 0.0369 - accuracy: 0.9880 - val_loss: 0.8656 - val_accuracy: 0.8354ss: 0.036\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.59911\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 272s 194ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.9858 - val_accuracy: 0.8384\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.59911\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 276s 196ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 1.0567 - val_accuracy: 0.8326\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.59911\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 277s 197ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.9908 - val_accuracy: 0.8436\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.59911\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 277s 197ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 1.0809 - val_accuracy: 0.8426\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.59911\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 277s 197ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 1.0339 - val_accuracy: 0.8406\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.59911\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 277s 197ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 1.0359 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.59911\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 277s 197ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 1.0401 - val_accuracy: 0.8472\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.59911\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 277s 197ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 1.0946 - val_accuracy: 0.8458\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.59911\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 276s 196ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 1.1873 - val_accuracy: 0.8502 - l\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.59911\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 277s 197ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 1.1787 - val_accuracy: 0.8484\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.59911\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 276s 196ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 1.2018 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.59911\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 278s 197ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 1.1901 - val_accuracy: 0.8470ETA: 21s - loss: 0.0021 - - ETA: 17s - loss:  - ETA: 13s - loss: 0.0020 - accurac - ETA: 11s - ETA: 3s - loss: 0.0020 - accuracy: 0.99 - ETA: 2s - loss: 0.0020  - ETA: 1s - loss: 0.0020 - ac\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.59911\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 277s 197ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 1.1846 - val_accuracy: 0.8504\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.59911\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 270s 192ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.2434 - val_accuracy: 0.8508\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.59911\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 270s 192ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 1.3111 - val_accuracy: 0.8468loss: 0.\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.59911\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 269s 192ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 1.2505 - val_accuracy: 0.8486\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.59911\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 269s 191ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.2568 - val_accuracy: 0.8510\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.59911\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 270s 192ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.2524 - val_accuracy: 0.8494\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.59911\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 275s 196ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.2421 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.59911\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 278s 198ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 1.2638 - val_accuracy: 0.8494\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.59911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15ac2672278>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer, loss 함수를 정의하고,  학습 준비를 한다,  metrics 는 어떤 일이 발생하는지 보여줄 것들\n",
    "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "# 한번에 몇개의 데이터 학습하고 가중치 갱신할지 \n",
    "model.fit(train_x, train_y,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          #validation_split = 0.1\n",
    "          validation_data = (valid_x, valid_y),\n",
    "          callbacks = [early_stop, reduce_lr , mc]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rxjhscjOR5w",
    "outputId": "597bc3a8-b80a-4e88-de02-dbda97b583bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 14s 46ms/step - loss: 1.3322 - accuracy: 0.84290s - loss: 1\n",
      "loss= 1.3322447538375854\n",
      "acc= 0.8428999781608582\n",
      "[3 1 1 ... 5 1 7]\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_x, test_y)\n",
    "print(\"loss=\",loss)\n",
    "print(\"acc=\",acc)\n",
    "\n",
    "y_ = model.predict(test_x)\n",
    "predicted = np.argmax(y_, axis=1)\n",
    "\n",
    "print(predicted)\n",
    "\n",
    "## 75.2\n",
    "## 67.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8AuRmRIqOTXd",
    "outputId": "b1baed42-f47a-4924-ffb7-17d4988046a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/resnet_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./saved_model/resnet_original.h5\")\n",
    "model.save(\"./saved_model/resnet_original_checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMQkmsTBOdJC"
   },
   "source": [
    "##int_8 Quantization 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8mdt9FmAOUj9"
   },
   "outputs": [],
   "source": [
    "# 구조까지 들어가 있는거\n",
    "model = tf.keras.models.load_model('./best_model/resnet_original_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mnkSbZd_Oc3R"
   },
   "outputs": [],
   "source": [
    "# input 에 대해서 변수 설정\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_x).batch(1).take(100):\n",
    "    yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5NJDbarOlhc",
    "outputId": "335fc300-1d60-42ff-9b1c-eb01e77fd395"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmp8jsirnfi\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n",
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    }
   ],
   "source": [
    "# int 8 로 quantization 진행하기\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qIfHHR7QOm60",
    "outputId": "beae9200-3143-4ffb-b74e-86a7405cc20c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmp5789r8cs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmp5789r8cs\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "# 그냥 파일 형태만 tflite로 변환 (float 형태임)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ncXY1MmKOobq",
    "outputId": "a4cd7d6d-68ed-4e39-9516-c61287abe357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tZXPnySKOo6w",
    "outputId": "5248bea5-b071-4771-8ed6-47a87d7fb765"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28475992"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 저장 해주는 과정\n",
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"./tflite/resnet_tflite/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the unquantized/float model:\n",
    "tflite_model_file = tflite_models_dir/\"resnet_original_tflite.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = tflite_models_dir/\"resnet_quantization_tflite.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Su6SO1CKOqLi"
   },
   "outputs": [],
   "source": [
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  global test_x\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = test_x[test_image_index]\n",
    "    test_label = test_y[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LqT2rNGPOrh5"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(tflite_file, model_type):\n",
    "  global test_x\n",
    "  global test_y\n",
    "\n",
    "  test_image_indices = range(test_x.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_image_indices)\n",
    "\n",
    "  accuracy = (np.sum(test_y.reshape(-1)== predictions) * 100) / len(test_x)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CPgDYzNWcnM",
    "outputId": "58fb64a3-7b2c-4c65-ab57-80db86dae74a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model accuracy is 79.4000% (Number of test samples=10000)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(tflite_model_file, model_type=\"Float\")\n",
    "evaluate_model(tflite_model_quant_file, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYzMVTwNOsi7"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pylab as plt\n",
    "\n",
    "# # Change this to test a different image\n",
    "# test_image_index = 1\n",
    "\n",
    "# ## Helper function to test the models on one image\n",
    "# def test_model(tflite_file, test_image_index, model_type):\n",
    "#   global test_labels\n",
    "\n",
    "#   predictions = run_tflite_model(tflite_file, [test_image_index])\n",
    "\n",
    "#   plt.imshow(test_x[test_image_index])\n",
    "#   template = model_type + \" Model \\n True:{true}, Predicted:{predict}\"\n",
    "#   _ = plt.title(template.format(true= str(test_y[test_image_index]), predict=str(predictions[0])))\n",
    "#   plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_wYKm4jOtj4"
   },
   "outputs": [],
   "source": [
    "# test_model(tflite_model_file, test_image_index, model_type=\"Float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ti97vld-Oume"
   },
   "outputs": [],
   "source": [
    "# test_model(tflite_model_quant_file, test_image_index, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q85dwKpQOwv1"
   },
   "source": [
    "##Pruning 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9SM32mkOvoT"
   },
   "outputs": [],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_x, test_y, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubhlv_QcOzEJ"
   },
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Dense, tfmot.sparsity.keras.PrunableLayer):\n",
    "\n",
    "  def get_prunable_weights(self):\n",
    "    # Prune bias also, though that usually harms model accuracy too much.\n",
    "    return [self.kernel, self.bias]\n",
    "\n",
    "# Use `prune_low_magnitude` to make the `MyDenseLayer` layer train with pruning.\n",
    "model_for_pruning = tf.keras.Sequential([\n",
    "  tfmot.sparsity.keras.prune_low_magnitude(MyDenseLayer(20, input_shape=input_shape)),\n",
    "  tf.keras.layers.Flatten()\n",
    "])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xh6Y4z3sO0AI"
   },
   "outputs": [],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_x.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGqo2IrqO0__"
   },
   "outputs": [],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_x, train_,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1PONfqRO165"
   },
   "outputs": [],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_x, test_y, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ur8LuxUO3ht"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ke3yltbMO4hd"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.\t경량 딥 러닝 기술 배경\n",
    "  1.\t기술 배경\n",
    "  2.\t기술 동향\n",
    "2.\t경량 알고리즘\n",
    "  1.\t모델 구조\n",
    "    1.\tResidual Block (Resnet)\n",
    "    2.\tDensely Connected Convolutional Networks (Densenet)\n",
    "    3.\tFire module (Squeezenet)\n",
    "  2.\t합성곱 필터 \n",
    "    1.\tDepthwise Convolution (mobilenet)\n",
    "    2.\tPointwise Convolution\n",
    "    3.\tDepthwise Separable Convolution\n",
    "  3.\t자동 모델 탐색\n",
    "    1.\tNetAdapt\n",
    "    2.\tMNasNet\n",
    "4.\t알고리즘 경량화\n",
    "  5.\t모델 압축\n",
    "    1.\tWeight Pruning\n",
    "    2.\tQuantization & Binarization \n",
    "  6.\t지식 증류\n",
    "    1.\t전문가 모델 – 숙련가 모델 \n",
    "  7.\t하드웨어 가속화\n",
    "    1.\tTPU\n",
    "    2.\tVPU\n",
    "    3.\t젝슨 TX2\n",
    "    4.\t퀄컴 스냅드래곤\n",
    "    5.\tA12 칩\n",
    "    6.\t엑시노스\n",
    "    7.\t등등 NPU \n",
    "  8.\t모델 압축 자동 탐색\n",
    "    1.\tTencent의 PocketFlow\n",
    "    2.\tAutoMC (Automated Model Compression)\t\n",
    "  9.\t실험 \n",
    "    1.\t비교 모델\n",
    "    2.\t개발 환경 및 code 구성\n",
    "    3 .\t성능 비교\n",
    "    4.\tInsight\n",
    "10.\t차주 계획\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNmT48vALjG+hejQmPj4Wuo",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MobileNet_V3_Small_예시.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
