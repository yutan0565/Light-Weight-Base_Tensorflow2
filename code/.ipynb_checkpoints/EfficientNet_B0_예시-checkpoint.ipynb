{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yutan0565/colab_git/blob/main/EfficientNet_B0_%EC%98%88%EC%8B%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HgXJWEEeK0D"
   },
   "source": [
    "## 기본 모델 형성\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dZanp6FNbbzM"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fO2RGXR2JRxq"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "import tensorflow_model_optimization as tfmot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "0ptbBJ19JRz_",
    "outputId": "68259ac5-7cde-4af6-db62-a641a5525837"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nprint(raw_train_x.shape)\\nprint(raw_test_x.shape)\\nprint(raw_train_y.shape)\\nprint(raw_test_y.shape)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "\"\"\"\n",
    "print(raw_train_x.shape)\n",
    "print(raw_test_x.shape)\n",
    "print(raw_train_y.shape)\n",
    "print(raw_test_y.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Y3XsyJumvC4Z",
    "outputId": "b7126bb9-334e-4f41-b350-05e43e49aca8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nprint(train_x.shape)\\nprint(valid_x.shape)\\nprint(test_x.shape)\\nprint(train_y.shape)\\nprint(valid_y.shape)\\nprint(test_y.shape)\\n\\ndef show_sample(i):\\n  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\\n  plt.imshow(raw_train_x[i])\\n  plt.show()\\n\\nfor i in [2, 10, 12, 14]:\\n  show_sample(i)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float을 넣을거면 0~1 사이 값으로 바꿔야함\n",
    "train_x = raw_train_x[:45000].astype(np.float32)/255.0\n",
    "valid_x = raw_train_x[45000:].astype(np.float32)/255.0\n",
    "test_x = raw_test_x.astype(np.float32)/255.0\n",
    "\n",
    "\n",
    "train_y = raw_train_y[:45000]\n",
    "valid_y = raw_train_y[45000:]\n",
    "test_y = raw_test_y\n",
    "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(train_x.shape)\n",
    "print(valid_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_y.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "def show_sample(i):\n",
    "  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\n",
    "  plt.imshow(raw_train_x[i])\n",
    "  plt.show()\n",
    "\n",
    "for i in [2, 10, 12, 14]:\n",
    "  show_sample(i)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1nLvUwGGvQ8w"
   },
   "outputs": [],
   "source": [
    "efficientnet  = EfficientNetB0(             # weights = 'imagenet',  그냥 초기화 하는거면, 이거 지우기\n",
    "                            include_top = False,\n",
    "                            input_shape=(32,32,3)\n",
    "                            )\n",
    "\n",
    "# vgg conv 구조만 사용하고 마지막 FC layer는 다른거 사용\n",
    "\n",
    "fc_layer = keras.Sequential([\n",
    "                             layers.Flatten(),\n",
    "                             layers.Dense(512, activation = 'relu'),\n",
    "                             layers.Dense(512, activation = 'relu'),\n",
    "                             layers.Dense(10, activation = \"sigmoid\")\n",
    "                             ])\n",
    "\n",
    "model = keras.Sequential([efficientnet,\n",
    "                          fc_layer\n",
    "                          ])\n",
    "\n",
    "# mobile.summary()\n",
    "# fc_layer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZ-LukhIvphi",
    "outputId": "9c05131d-bb20-4851-e00d-155fa855467c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 443s 1s/step - loss: 1.3117 - accuracy: 0.5380 - val_loss: 3.8236 - val_accuracy: 0.1036 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f48001cbc90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(patience=20) \n",
    "#mc = ModelCheckpoint(\"/check_point.h5\", save_best_only=True) \n",
    "reduce_lr  = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                               factor=0.1, \n",
    "                               patience=5\n",
    "                               ) \n",
    "csvlogger = CSVLogger(\"model_log.log\") \n",
    "\n",
    "\n",
    "# optimizer, loss 함수를 정의하고,  학습 준비를 한다,  metrics 는 어떤 일이 발생하는지 보여줄 것들\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "# 한번에 몇개의 데이터 학습하고 가중치 갱신할지 \n",
    "model.fit(train_x, train_y,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          batch_size=128,\n",
    "          #validation_split = 0.1\n",
    "          validation_data = (valid_x, valid_y),\n",
    "          callbacks = [es, reduce_lr , csvlogger]\n",
    "          )\n",
    "\n",
    "# call back 참고 : https://deep-deep-deep.tistory.com/1 들어가면 여러 옵션들이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIGR4cUIFFFG",
    "outputId": "bc7cb997-8189-4e51-a425-e357c452b7f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 14s 44ms/step - loss: 3.8019 - accuracy: 0.1070\n",
      "loss= 3.8018929958343506\n",
      "acc= 0.10700000077486038\n",
      "[4 4 2 ... 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_x, test_y)\n",
    "print(\"loss=\",loss)\n",
    "print(\"acc=\",acc)\n",
    "\n",
    "y_ = model.predict(test_x)\n",
    "predicted = np.argmax(y_, axis=1)\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./saved_model/mobile_original.h5\")\n",
    "model.save(\"./saved_model/mobile_original_checkpoint.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWaTjCHHeZJJ"
   },
   "source": [
    "## int_8 Quantization 진행\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kR1YvGr6TqB0"
   },
   "outputs": [],
   "source": [
    "# 구조까지 들어가 있는거\n",
    "#model_load = tf.keras.models.load_model('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "K_pCuwiQSAec"
   },
   "outputs": [],
   "source": [
    "# input 에 대해서 변수 설정\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_x).batch(1).take(100):\n",
    "    yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvxpgAD7SAvS",
    "outputId": "8e46a603-d034-47a1-a0ab-72280e005257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpibqvmfw2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "# int 8 로 quantization 진행하기\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLjaFd7wavtS",
    "outputId": "9eb111bd-d091-42cc-df14-33caff6c094a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe5qstfn9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe5qstfn9/assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "# 그냥 파일 형태만 tflite로 변환 (float 형태임)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8xyG2LcUUJT9",
    "outputId": "fa4654b9-7c1e-438b-c75c-65e70af35c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZdR24DrHUfpg",
    "outputId": "33ccb621-acf8-41bb-f4bd-c7aaef1ea86c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5843736"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 저장 해주는 과정\n",
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"/tmp/mobile_tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the unquantized/float model:\n",
    "tflite_model_file = tflite_models_dir/\"mobile_model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = tflite_models_dir/\"mobiile_model_quant.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sAK1WC33UfxT"
   },
   "outputs": [],
   "source": [
    "# tensorlffow lite 모델 실행 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "13myIyvtcyto"
   },
   "outputs": [],
   "source": [
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  global test_x\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = test_x[test_image_index]\n",
    "    test_label = test_y[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Lv1HJGcxcJR9"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(tflite_file, model_type):\n",
    "  global test_x\n",
    "  global test_y\n",
    "\n",
    "  test_image_indices = range(test_x.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_image_indices)\n",
    "\n",
    "  accuracy = (np.sum(test_y.reshape(-1)== predictions) * 100) / len(test_x)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(test_x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bac0X0MIcJ-y",
    "outputId": "4e277393-0378-4fbe-ddad-ae9ba5772882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model accuracy is 10.7000% (Number of test samples=10000)\n",
      "[4 4 2 ... 4 4 4]\n",
      "[3 8 8 ... 5 1 7]\n",
      "Quantized model accuracy is 11.0200% (Number of test samples=10000)\n",
      "[4 6 6 ... 6 6 2]\n",
      "[3 8 8 ... 5 1 7]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(tflite_model_file, model_type=\"Float\")\n",
    "evaluate_model(tflite_model_quant_file, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "wJ8BqBRecLa_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Change this to test a different image\n",
    "test_image_index = 1\n",
    "\n",
    "## Helper function to test the models on one image\n",
    "def test_model(tflite_file, test_image_index, model_type):\n",
    "  global test_labels\n",
    "\n",
    "  predictions = run_tflite_model(tflite_file, [test_image_index])\n",
    "\n",
    "  plt.imshow(test_x[test_image_index])\n",
    "  template = model_type + \" Model \\n True:{true}, Predicted:{predict}\"\n",
    "  _ = plt.title(template.format(true= str(test_y[test_image_index]), predict=str(predictions[0])))\n",
    "  plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "kgJlkK8kdnKT",
    "outputId": "f12c7fce-cfd6-4c79-a364-ee9d3c69eb9c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_model(tflite_model_file, test_image_index, model_type=\"Float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "XWXNXX5ydpG5",
    "outputId": "235a49d4-fcbb-4f6f-9464-3b95d576b4ee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_model(tflite_model_quant_file, test_image_index, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm0ntodhlF8y"
   },
   "source": [
    "## Pruning 진행\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjlumF76nDzo",
    "outputId": "9d4ea0c3-63c1-4998-ffa2-fbfe3a90256d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.10700000077486038\n",
      "Saved baseline model to: /tmp/tmp3kffawg1.h5\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_x, test_y, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "dET8FyEYnZdG",
    "outputId": "425f0181-f55b-457b-d4b3-13a4592e4978"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f9c5c3f01e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m }\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel_for_pruning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprune_low_magnitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpruning_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# `prune_low_magnitude` requires a recompile.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/keras/metrics.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMonitorBoolGauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FAILURE_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_gauge\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/keras/metrics.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMonitorBoolGauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUCCESS_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py\u001b[0m in \u001b[0;36mprune_low_magnitude\u001b[0;34m(to_prune, pruning_schedule, block_size, block_pooling_type, pruning_policy, sparsity_m_by_n, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpruning_policy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mpruning_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_model_supports_pruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_prune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_add_pruning_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_prune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mis_keras_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py\u001b[0m in \u001b[0;36m_add_pruning_wrapper\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       return keras.models.clone_model(\n\u001b[0;32m--> 182\u001b[0;31m           layer, input_tensors=None, clone_function=_add_pruning_wrapper)\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruning_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPruneLowMagnitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m       return _clone_sequential_model(\n\u001b[0;32m--> 454\u001b[0;31m           model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m       return _clone_functional_model(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    328\u001b[0m     cloned_layer = (\n\u001b[1;32m    329\u001b[0m         \u001b[0m_clone_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         if isinstance(layer, InputLayer) else layer_fn(layer))\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloned_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0mlayer_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloned_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py\u001b[0m in \u001b[0;36m_add_pruning_wrapper\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       return keras.models.clone_model(\n\u001b[0;32m--> 182\u001b[0;31m           layer, input_tensors=None, clone_function=_add_pruning_wrapper)\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruning_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPruneLowMagnitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m       return _clone_functional_model(\n\u001b[0;32m--> 457\u001b[0;31m           model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36m_clone_functional_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m   model_configs, created_layers = _clone_layers_and_model_config(\n\u001b[0;32m--> 194\u001b[0;31m       model, new_input_layers, layer_fn)\n\u001b[0m\u001b[1;32m    195\u001b[0m   \u001b[0;31m# Reconstruct model from the config, using the cloned layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m   input_tensors, output_tensors, created_layers = (\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36m_clone_layers_and_model_config\u001b[0;34m(model, input_layers, layer_fn)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m   config = functional.get_network_config(\n\u001b[0;32m--> 247\u001b[0;31m       model, serialize_layer_fn=_copy_layer)\n\u001b[0m\u001b[1;32m    248\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m       \u001b[0mlayer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_layer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m       \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m       \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inbound_nodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36m_copy_layer\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m       \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py\u001b[0m in \u001b[0;36m_add_pruning_wrapper\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mpruning_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPruneLowMagnitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m   params = {\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer, pruning_schedule, block_size, block_pooling_type, sparsity_m_by_n, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m           \u001b[0;34m'should be a `PrunableLayer` instance, or should has a customer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m           \u001b[0;34m'defined `get_prunable_weights` method. You passed: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m           '{input}'.format(input=layer.__class__))\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_track_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please initialize `Prune` with a supported layer. Layers should either be supported by the PruneRegistry (built-in keras layers) or should be a `PrunableLayer` instance, or should has a customer defined `get_prunable_weights` method. You passed: <class 'keras.layers.preprocessing.image_preprocessing.Rescaling'>"
     ]
    }
   ],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_x.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4voFQPDRyuWG"
   },
   "outputs": [],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_x, train_,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tESxUKGaf5Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtnCY7h-y0Fd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRZDWu6V4A9w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTuWeu5d4BBs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bF_0FHG4BHX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctE1qnS24BO3",
    "outputId": "83c86f5d-506a-4507-962a-f4f586998a0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Epoch 1/4\n",
      "1688/1688 [==============================] - 18s 10ms/step - loss: 0.2956 - accuracy: 0.9167 - val_loss: 0.1110 - val_accuracy: 0.9727\n",
      "Epoch 2/4\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.1095 - accuracy: 0.9693 - val_loss: 0.0766 - val_accuracy: 0.9818\n",
      "Epoch 3/4\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0780 - accuracy: 0.9775 - val_loss: 0.0671 - val_accuracy: 0.9828\n",
      "Epoch 4/4\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0641 - accuracy: 0.9816 - val_loss: 0.0599 - val_accuracy: 0.9843\n",
      "Baseline test accuracy: 0.9797000288963318\n",
      "Saved baseline model to: /tmp/tmp2dy64kik.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:238: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  trainable=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_reshape  (None, 28, 28, 1)        1         \n",
      " _4 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 26, 26, 12)       230       \n",
      " 4 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 13, 13, 12)       1         \n",
      " ling2d_4 (PruneLowMagnitude                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 2028)             1         \n",
      " _5 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_7  (None, 10)               40572     \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,805\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 20,395\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:218: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  aggregation=tf.VariableAggregation.MEAN)\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:225: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  aggregation=tf.VariableAggregation.MEAN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "422/422 [==============================] - 15s 29ms/step - loss: 0.0798 - accuracy: 0.9784 - val_loss: 0.0825 - val_accuracy: 0.9790\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 17s 39ms/step - loss: 0.0861 - accuracy: 0.9771 - val_loss: 0.0760 - val_accuracy: 0.9798\n",
      "Baseline test accuracy: 0.9797000288963318\n",
      "Pruned test accuracy: 0.9747999906539917\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "%load_ext tensorboard\n",
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ")\n",
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()\n",
    "\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)\n",
    "\n",
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "czJQDfUvsPel"
   },
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()\n",
    "\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)\n",
    "\n",
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONfJDO9Gg5O+ULxRnQGC1z",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1Et-iwTi6UUUc5F1_JvqO-_LjfL43QBV_",
   "name": "EfficientNet_B0_예시.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
