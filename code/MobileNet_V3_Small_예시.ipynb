{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yutan0565/colab_git/blob/main/code/MobileNet_V3_Small_%EC%98%88%EC%8B%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTOd0ahJOZsr"
   },
   "source": [
    "##기본 모델 형성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNI1wdG4N7yF",
    "outputId": "2080654c-6979-443e-9516-da8a3f2f40f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |█▍                              | 10 kB 20.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 20 kB 22.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 30 kB 27.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 40 kB 16.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 51 kB 14.5 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 61 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 71 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 81 kB 14.0 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 92 kB 15.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 102 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 112 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 122 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 133 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 143 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 153 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 163 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 174 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 184 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 194 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 204 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 215 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 225 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 235 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 237 kB 16.3 MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pZRQ2Jc4OCS1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "7R6Yikb4OCuf",
    "outputId": "c2fdef5f-6db2-40a4-c2c4-a76675e44fc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n",
      "170508288/170498071 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nprint(raw_train_x.shape)\\nprint(raw_test_x.shape)\\nprint(raw_train_y.shape)\\nprint(raw_test_y.shape)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "\"\"\"\n",
    "print(raw_train_x.shape)\n",
    "print(raw_test_x.shape)\n",
    "print(raw_train_y.shape)\n",
    "print(raw_test_y.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "yuQ_qeDSODzw",
    "outputId": "13f56c8b-6d6b-4024-bf7f-68d821b8e578"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nprint(train_x.shape)\\nprint(valid_x.shape)\\nprint(test_x.shape)\\nprint(train_y.shape)\\nprint(valid_y.shape)\\nprint(test_y.shape)\\n\\ndef show_sample(i):\\n  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\\n  plt.imshow(raw_train_x[i])\\n  plt.show()\\n\\nfor i in [2, 10, 12, 14]:\\n  show_sample(i)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float을 넣을거면 0~1 사이 값으로 바꿔야함\n",
    "# integer 형태로 넣어보기\n",
    "train_x = raw_train_x[:45000].astype(np.float32)/255.0\n",
    "valid_x = raw_train_x[45000:].astype(np.float32)/255.0\n",
    "test_x = raw_test_x.astype(np.float32)/255.0\n",
    "\n",
    "\n",
    "train_y = raw_train_y[:45000]\n",
    "valid_y = raw_train_y[45000:]\n",
    "test_y = raw_test_y\n",
    "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(train_x.shape)\n",
    "print(valid_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_y.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "def show_sample(i):\n",
    "  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\n",
    "  plt.imshow(raw_train_x[i])\n",
    "  plt.show()\n",
    "\n",
    "for i in [2, 10, 12, 14]:\n",
    "  show_sample(i)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wwn3NFrmOFeq",
    "outputId": "39e134ed-bbd7-4d3b-84b3-18c23da45a40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
      "4341760/4334752 [==============================] - 0s 0us/step\n",
      "4349952/4334752 [==============================] - 0s 0us/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " MobilenetV3small (Functiona  (None, 1, 1, 576)        939120    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 10)                2700298   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,639,418\n",
      "Trainable params: 3,627,306\n",
      "Non-trainable params: 12,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile = MobileNetV3Small(  #weights = 'imagenet',  #그냥 초기화 하는거면, 이거 지우기\n",
    "                            include_top = False,\n",
    "                            input_shape=(32,32,3)\n",
    "                            )\n",
    "\n",
    "# vgg conv 구조만 사용하고 마지막 FC layer는 다른거 사용\n",
    "\n",
    "fc_layer = keras.Sequential([\n",
    "                             layers.Flatten(),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(10, activation = \"sigmoid\")\n",
    "                             ])\n",
    "\n",
    "model = keras.Sequential([mobile,\n",
    "                          fc_layer\n",
    "                          ])\n",
    "model.summary()\n",
    "# mobile.summary()\n",
    "# fc_layer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VuUFfKa1OIUa"
   },
   "outputs": [],
   "source": [
    "# Callback 함수 지정 해주기\n",
    "early_stop = EarlyStopping(patience=30) \n",
    "mc = ModelCheckpoint(\"./best_model/mobile_original_checkpoint\", \n",
    "                     save_best_only=True,\n",
    "                     monitor = 'val_loss',\n",
    "                     verbose = 1,\n",
    "                     mode = 'min') \n",
    "reduce_lr  = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                               factor=0.5, \n",
    "                               patience=5\n",
    "                               ) \n",
    "# tensorboard 관련 \n",
    "def make_Tensorboard_dir(dir_name):\n",
    "  root_logdir = os.path.join(os.curdir, dir_name)\n",
    "  sub_dir_name = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  return os.path.join(root_logdir, sub_dir_name)\n",
    "\n",
    "dir_name = \"Learning_log\"\n",
    "TB_log_dir = make_Tensorboard_dir(dir_name)\n",
    "TensorB = TensorBoard(log_dir = TB_log_dir)\n",
    "\n",
    "\n",
    "#optimizaer  조정 해주기\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3K9FF5gmOLH6",
    "outputId": "2f7c3f80-6d86-4397-f4c1-d892168f980c"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 0.9037\n",
      "Epoch 1: val_loss improved from inf to 2.75490, saving model to ./best_model/mobile_original_checkpoint\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/mobile_original_checkpoint/assets\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/mobile_original_checkpoint/assets\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 195s 135ms/step - loss: 0.2679 - accuracy: 0.9037 - val_loss: 2.7549 - val_accuracy: 0.5326 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.9034\n",
      "Epoch 2: val_loss did not improve from 2.75490\n",
      "1407/1407 [==============================] - 162s 115ms/step - loss: 0.2673 - accuracy: 0.9034 - val_loss: 3.1651 - val_accuracy: 0.4180 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 0.2667 - accuracy: 0.9042\n",
      "Epoch 3: val_loss did not improve from 2.75490\n",
      "1407/1407 [==============================] - 158s 112ms/step - loss: 0.2670 - accuracy: 0.9041 - val_loss: 5.7843 - val_accuracy: 0.2540 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.9051\n",
      "Epoch 4: val_loss improved from 2.75490 to 2.28420, saving model to ./best_model/mobile_original_checkpoint\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/mobile_original_checkpoint/assets\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/mobile_original_checkpoint/assets\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 183s 130ms/step - loss: 0.2602 - accuracy: 0.9051 - val_loss: 2.2842 - val_accuracy: 0.5126 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.9061\n",
      "Epoch 5: val_loss did not improve from 2.28420\n",
      "1407/1407 [==============================] - 158s 112ms/step - loss: 0.2573 - accuracy: 0.9061 - val_loss: 36.3684 - val_accuracy: 0.1632 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2557 - accuracy: 0.9084\n",
      "Epoch 6: val_loss did not improve from 2.28420\n",
      "1407/1407 [==============================] - 156s 111ms/step - loss: 0.2557 - accuracy: 0.9084 - val_loss: 20.0756 - val_accuracy: 0.1840 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9120\n",
      "Epoch 7: val_loss improved from 2.28420 to 1.62492, saving model to ./best_model/mobile_original_checkpoint\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/mobile_original_checkpoint/assets\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/mobile_original_checkpoint/assets\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 182s 129ms/step - loss: 0.2449 - accuracy: 0.9120 - val_loss: 1.6249 - val_accuracy: 0.6374 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 0.2386 - accuracy: 0.9135\n",
      "Epoch 8: val_loss did not improve from 1.62492\n",
      "1407/1407 [==============================] - 160s 114ms/step - loss: 0.2387 - accuracy: 0.9135 - val_loss: 2.5678 - val_accuracy: 0.5070 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2387 - accuracy: 0.9143\n",
      "Epoch 9: val_loss did not improve from 1.62492\n",
      "1407/1407 [==============================] - 162s 115ms/step - loss: 0.2387 - accuracy: 0.9143 - val_loss: 5.3435 - val_accuracy: 0.2534 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.9136\n",
      "Epoch 10: val_loss did not improve from 1.62492\n",
      "1407/1407 [==============================] - 162s 115ms/step - loss: 0.2405 - accuracy: 0.9136 - val_loss: 4.9445 - val_accuracy: 0.3212 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.9145\n",
      "Epoch 11: val_loss did not improve from 1.62492\n",
      "1407/1407 [==============================] - 159s 113ms/step - loss: 0.2360 - accuracy: 0.9145 - val_loss: 5.9275 - val_accuracy: 0.2874 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9196\n",
      "Epoch 12: val_loss did not improve from 1.62492\n",
      "1407/1407 [==============================] - 161s 114ms/step - loss: 0.2261 - accuracy: 0.9196 - val_loss: 3.2253 - val_accuracy: 0.4030 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.9243\n",
      "Epoch 13: val_loss improved from 1.62492 to 1.59783, saving model to ./best_model/mobile_original_checkpoint\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/mobile_original_checkpoint/assets\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/mobile_original_checkpoint/assets\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 186s 132ms/step - loss: 0.2125 - accuracy: 0.9243 - val_loss: 1.5978 - val_accuracy: 0.6434 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2034 - accuracy: 0.9261\n",
      "Epoch 14: val_loss did not improve from 1.59783\n",
      "1407/1407 [==============================] - 165s 118ms/step - loss: 0.2034 - accuracy: 0.9261 - val_loss: 2.2736 - val_accuracy: 0.5834 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2046 - accuracy: 0.9270\n",
      "Epoch 15: val_loss improved from 1.59783 to 1.56508, saving model to ./best_model/mobile_original_checkpoint\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/mobile_original_checkpoint/assets\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/mobile_original_checkpoint/assets\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 187s 133ms/step - loss: 0.2046 - accuracy: 0.9270 - val_loss: 1.5651 - val_accuracy: 0.6686 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.9276\n",
      "Epoch 16: val_loss did not improve from 1.56508\n",
      "1407/1407 [==============================] - 165s 117ms/step - loss: 0.2017 - accuracy: 0.9276 - val_loss: 2.2980 - val_accuracy: 0.5850 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2004 - accuracy: 0.9291\n",
      "Epoch 17: val_loss did not improve from 1.56508\n",
      "1407/1407 [==============================] - 166s 118ms/step - loss: 0.2004 - accuracy: 0.9291 - val_loss: 1.7830 - val_accuracy: 0.6060 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1959 - accuracy: 0.9304\n",
      "Epoch 18: val_loss did not improve from 1.56508\n",
      "1407/1407 [==============================] - 165s 117ms/step - loss: 0.1959 - accuracy: 0.9304 - val_loss: 2.3637 - val_accuracy: 0.5626 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.9334\n",
      "Epoch 19: val_loss did not improve from 1.56508\n",
      "1407/1407 [==============================] - 165s 117ms/step - loss: 0.1873 - accuracy: 0.9334 - val_loss: 4.3594 - val_accuracy: 0.4034 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.9316\n",
      "Epoch 20: val_loss did not improve from 1.56508\n",
      "1407/1407 [==============================] - 164s 117ms/step - loss: 0.1910 - accuracy: 0.9316 - val_loss: 24.7602 - val_accuracy: 0.1806 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1812 - accuracy: 0.9353\n",
      "Epoch 21: val_loss did not improve from 1.56508\n",
      "1407/1407 [==============================] - 166s 118ms/step - loss: 0.1812 - accuracy: 0.9353 - val_loss: 2.1657 - val_accuracy: 0.6066 - lr: 2.5000e-05\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.9358\n",
      "Epoch 22: val_loss did not improve from 1.56508\n",
      "1407/1407 [==============================] - 162s 115ms/step - loss: 0.1814 - accuracy: 0.9358 - val_loss: 4.3102 - val_accuracy: 0.3788 - lr: 2.5000e-05\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.9364\n",
      "Epoch 23: val_loss did not improve from 1.56508\n",
      "1407/1407 [==============================] - 161s 114ms/step - loss: 0.1772 - accuracy: 0.9364 - val_loss: 1.7023 - val_accuracy: 0.6550 - lr: 2.5000e-05\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1828 - accuracy: 0.9338\n",
      "Epoch 24: val_loss did not improve from 1.56508\n",
      "1407/1407 [==============================] - 162s 115ms/step - loss: 0.1828 - accuracy: 0.9338 - val_loss: 2.8724 - val_accuracy: 0.5392 - lr: 2.5000e-05\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.9379\n",
      "Epoch 25: val_loss did not improve from 1.56508\n",
      "1407/1407 [==============================] - 159s 113ms/step - loss: 0.1760 - accuracy: 0.9379 - val_loss: 1.8555 - val_accuracy: 0.6308 - lr: 2.5000e-05\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1789 - accuracy: 0.9375\n",
      "Epoch 26: val_loss improved from 1.56508 to 1.42941, saving model to ./best_model/mobile_original_checkpoint\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/mobile_original_checkpoint/assets\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/mobile_original_checkpoint/assets\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 184s 131ms/step - loss: 0.1789 - accuracy: 0.9375 - val_loss: 1.4294 - val_accuracy: 0.6988 - lr: 1.2500e-05\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.9382\n",
      "Epoch 27: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 161s 114ms/step - loss: 0.1743 - accuracy: 0.9382 - val_loss: 1.4311 - val_accuracy: 0.7048 - lr: 1.2500e-05\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9394\n",
      "Epoch 28: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 161s 115ms/step - loss: 0.1694 - accuracy: 0.9394 - val_loss: 1.4662 - val_accuracy: 0.6950 - lr: 1.2500e-05\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9384\n",
      "Epoch 29: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 161s 114ms/step - loss: 0.1741 - accuracy: 0.9384 - val_loss: 1.4403 - val_accuracy: 0.7018 - lr: 1.2500e-05\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9404\n",
      "Epoch 30: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 160s 114ms/step - loss: 0.1704 - accuracy: 0.9404 - val_loss: 1.6537 - val_accuracy: 0.6488 - lr: 1.2500e-05\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1665 - accuracy: 0.9397\n",
      "Epoch 31: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 159s 113ms/step - loss: 0.1665 - accuracy: 0.9397 - val_loss: 1.4827 - val_accuracy: 0.6926 - lr: 1.2500e-05\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.9415\n",
      "Epoch 32: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 161s 115ms/step - loss: 0.1640 - accuracy: 0.9415 - val_loss: 1.5474 - val_accuracy: 0.6764 - lr: 6.2500e-06\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1622 - accuracy: 0.9416\n",
      "Epoch 33: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 161s 115ms/step - loss: 0.1622 - accuracy: 0.9416 - val_loss: 1.5380 - val_accuracy: 0.6860 - lr: 6.2500e-06\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1664 - accuracy: 0.9396\n",
      "Epoch 34: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 162s 115ms/step - loss: 0.1664 - accuracy: 0.9396 - val_loss: 1.5249 - val_accuracy: 0.6852 - lr: 6.2500e-06\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.9412\n",
      "Epoch 35: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 162s 115ms/step - loss: 0.1648 - accuracy: 0.9412 - val_loss: 1.4546 - val_accuracy: 0.7064 - lr: 6.2500e-06\n",
      "Epoch 36/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 0.1658 - accuracy: 0.9411\n",
      "Epoch 36: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 160s 114ms/step - loss: 0.1661 - accuracy: 0.9410 - val_loss: 1.5020 - val_accuracy: 0.6964 - lr: 6.2500e-06\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.9407\n",
      "Epoch 37: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 159s 113ms/step - loss: 0.1651 - accuracy: 0.9407 - val_loss: 1.4596 - val_accuracy: 0.7068 - lr: 3.1250e-06\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.9426\n",
      "Epoch 38: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 153s 109ms/step - loss: 0.1614 - accuracy: 0.9426 - val_loss: 1.4591 - val_accuracy: 0.6984 - lr: 3.1250e-06\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9415\n",
      "Epoch 39: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 157s 112ms/step - loss: 0.1616 - accuracy: 0.9415 - val_loss: 1.4555 - val_accuracy: 0.7060 - lr: 3.1250e-06\n",
      "Epoch 40/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 0.1608 - accuracy: 0.9426\n",
      "Epoch 40: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 155s 110ms/step - loss: 0.1610 - accuracy: 0.9426 - val_loss: 1.4650 - val_accuracy: 0.6998 - lr: 3.1250e-06\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1597 - accuracy: 0.9436\n",
      "Epoch 41: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 158s 112ms/step - loss: 0.1597 - accuracy: 0.9436 - val_loss: 1.4950 - val_accuracy: 0.6986 - lr: 3.1250e-06\n",
      "Epoch 42/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 0.1545 - accuracy: 0.9448\n",
      "Epoch 42: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 159s 113ms/step - loss: 0.1548 - accuracy: 0.9447 - val_loss: 1.4666 - val_accuracy: 0.7032 - lr: 1.5625e-06\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1586 - accuracy: 0.9435\n",
      "Epoch 43: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 154s 109ms/step - loss: 0.1586 - accuracy: 0.9435 - val_loss: 1.4590 - val_accuracy: 0.7062 - lr: 1.5625e-06\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.9436\n",
      "Epoch 44: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 155s 110ms/step - loss: 0.1578 - accuracy: 0.9436 - val_loss: 1.4668 - val_accuracy: 0.7046 - lr: 1.5625e-06\n",
      "Epoch 45/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 0.1603 - accuracy: 0.9432\n",
      "Epoch 45: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 156s 111ms/step - loss: 0.1603 - accuracy: 0.9432 - val_loss: 1.4657 - val_accuracy: 0.7044 - lr: 1.5625e-06\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1585 - accuracy: 0.9441\n",
      "Epoch 46: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 158s 112ms/step - loss: 0.1585 - accuracy: 0.9441 - val_loss: 1.4752 - val_accuracy: 0.7014 - lr: 1.5625e-06\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.9437\n",
      "Epoch 47: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 155s 110ms/step - loss: 0.1592 - accuracy: 0.9437 - val_loss: 1.4626 - val_accuracy: 0.7078 - lr: 7.8125e-07\n",
      "Epoch 48/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 0.1608 - accuracy: 0.9421\n",
      "Epoch 48: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 152s 108ms/step - loss: 0.1608 - accuracy: 0.9421 - val_loss: 1.4610 - val_accuracy: 0.7066 - lr: 7.8125e-07\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.9438\n",
      "Epoch 49: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 155s 111ms/step - loss: 0.1615 - accuracy: 0.9438 - val_loss: 1.4638 - val_accuracy: 0.7040 - lr: 7.8125e-07\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.9425\n",
      "Epoch 50: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 156s 111ms/step - loss: 0.1633 - accuracy: 0.9425 - val_loss: 1.4595 - val_accuracy: 0.7064 - lr: 7.8125e-07\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1602 - accuracy: 0.9428\n",
      "Epoch 51: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 156s 111ms/step - loss: 0.1602 - accuracy: 0.9428 - val_loss: 1.4621 - val_accuracy: 0.7034 - lr: 7.8125e-07\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.9412\n",
      "Epoch 52: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 155s 110ms/step - loss: 0.1601 - accuracy: 0.9412 - val_loss: 1.4612 - val_accuracy: 0.7072 - lr: 3.9062e-07\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.9426\n",
      "Epoch 53: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 156s 111ms/step - loss: 0.1619 - accuracy: 0.9426 - val_loss: 1.4610 - val_accuracy: 0.7084 - lr: 3.9062e-07\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1657 - accuracy: 0.9405\n",
      "Epoch 54: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 155s 110ms/step - loss: 0.1657 - accuracy: 0.9405 - val_loss: 1.4580 - val_accuracy: 0.7054 - lr: 3.9062e-07\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.9417\n",
      "Epoch 55: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 157s 111ms/step - loss: 0.1619 - accuracy: 0.9417 - val_loss: 1.4590 - val_accuracy: 0.7076 - lr: 3.9062e-07\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9435\n",
      "Epoch 56: val_loss did not improve from 1.42941\n",
      "1407/1407 [==============================] - 155s 110ms/step - loss: 0.1630 - accuracy: 0.9435 - val_loss: 1.4577 - val_accuracy: 0.7072 - lr: 3.9062e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdeef8f4410>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer, loss 함수를 정의하고,  학습 준비를 한다,  metrics 는 어떤 일이 발생하는지 보여줄 것들\n",
    "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "# 한번에 몇개의 데이터 학습하고 가중치 갱신할지 \n",
    "model.fit(train_x, train_y,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          #validation_split = 0.1\n",
    "          validation_data = (valid_x, valid_y),\n",
    "          callbacks = [early_stop, reduce_lr , mc]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rxjhscjOR5w",
    "outputId": "597bc3a8-b80a-4e88-de02-dbda97b583bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 23ms/step - loss: 2.3950 - accuracy: 0.5545\n",
      "loss= 2.3950114250183105\n",
      "acc= 0.5544999837875366\n",
      "[1 8 0 ... 0 0 7]\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_x, test_y)\n",
    "print(\"loss=\",loss)\n",
    "print(\"acc=\",acc)\n",
    "\n",
    "y_ = model.predict(test_x)\n",
    "predicted = np.argmax(y_, axis=1)\n",
    "\n",
    "print(predicted)\n",
    "\n",
    "## 75.2\n",
    "## 67.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8AuRmRIqOTXd",
    "outputId": "b1baed42-f47a-4924-ffb7-17d4988046a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/mobile_original_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/mobile_original_checkpoint/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./saved_model/mobile_original.h5\")\n",
    "model.save(\"./saved_model/mobile_original_checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMQkmsTBOdJC"
   },
   "source": [
    "##int_8 Quantization 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8mdt9FmAOUj9"
   },
   "outputs": [],
   "source": [
    "# 구조까지 들어가 있는거\n",
    "model = tf.keras.models.load_model('./best_model/mobile_original_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "mnkSbZd_Oc3R"
   },
   "outputs": [],
   "source": [
    "# input 에 대해서 변수 설정\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_x).batch(1).take(100):\n",
    "    yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5NJDbarOlhc",
    "outputId": "335fc300-1d60-42ff-9b1c-eb01e77fd395"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpp7nel5ke/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpp7nel5ke/assets\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "# int 8 로 quantization 진행하기\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qIfHHR7QOm60",
    "outputId": "beae9200-3143-4ffb-b74e-86a7405cc20c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7nxp71hl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7nxp71hl/assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "# 그냥 파일 형태만 tflite로 변환 (float 형태임)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ncXY1MmKOobq",
    "outputId": "a4cd7d6d-68ed-4e39-9516-c61287abe357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tZXPnySKOo6w",
    "outputId": "5248bea5-b071-4771-8ed6-47a87d7fb765"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3939416"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 저장 해주는 과정\n",
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"./tflite/mobile_tflite/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the unquantized/float model:\n",
    "tflite_model_file = tflite_models_dir/\"mobile_original_tflite.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = tflite_models_dir/\"mobiile_quantization_tflite.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Su6SO1CKOqLi"
   },
   "outputs": [],
   "source": [
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  global test_x\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = test_x[test_image_index]\n",
    "    test_label = test_y[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "LqT2rNGPOrh5"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(tflite_file, model_type):\n",
    "  global test_x\n",
    "  global test_y\n",
    "\n",
    "  test_image_indices = range(test_x.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_image_indices)\n",
    "\n",
    "  accuracy = (np.sum(test_y.reshape(-1)== predictions) * 100) / len(test_x)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CPgDYzNWcnM",
    "outputId": "58fb64a3-7b2c-4c65-ab57-80db86dae74a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model accuracy is 67.8900% (Number of test samples=10000)\n",
      "Quantized model accuracy is 30.2500% (Number of test samples=10000)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(tflite_model_file, model_type=\"Float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(tflite_model_quant_file, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tflite_time(tflite_file, test_image_indices):\n",
    "  global test_x\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = test_x[test_image_index]\n",
    "    test_label = test_y[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "        \n",
    "    start = time.time()\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    end = time.time()\n",
    "    \n",
    "    fps = 1 / (end - start)\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYzMVTwNOsi7"
   },
   "outputs": [],
   "source": [
    "# Change this to test a different image\n",
    "test_image_index = 1\n",
    "\n",
    "def test_model_time(tflite_file, test_image_index, model_type):\n",
    "  global test_y\n",
    "  fps = run_tflite_time(tflite_file, [test_image_index])\n",
    "  print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_wYKm4jOtj4"
   },
   "outputs": [],
   "source": [
    "test_model_time(tflite_model_file, test_image_index, model_type=\"Float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ti97vld-Oume"
   },
   "outputs": [],
   "source": [
    "test_model_time(tflite_model_quant_file, test_image_index, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q85dwKpQOwv1"
   },
   "source": [
    "##Pruning 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9SM32mkOvoT"
   },
   "outputs": [],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_x, test_y, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubhlv_QcOzEJ"
   },
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Dense, tfmot.sparsity.keras.PrunableLayer):\n",
    "\n",
    "  def get_prunable_weights(self):\n",
    "    # Prune bias also, though that usually harms model accuracy too much.\n",
    "    return [self.kernel, self.bias]\n",
    "\n",
    "# Use `prune_low_magnitude` to make the `MyDenseLayer` layer train with pruning.\n",
    "model_for_pruning = tf.keras.Sequential([\n",
    "  tfmot.sparsity.keras.prune_low_magnitude(MyDenseLayer(20, input_shape=input_shape)),\n",
    "  tf.keras.layers.Flatten()\n",
    "])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xh6Y4z3sO0AI"
   },
   "outputs": [],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_x.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGqo2IrqO0__"
   },
   "outputs": [],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_x, train_,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1PONfqRO165"
   },
   "outputs": [],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_x, test_y, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ur8LuxUO3ht"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ke3yltbMO4hd"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.\t경량 딥 러닝 기술 배경\n",
    "  1.\t기술 배경\n",
    "  2.\t기술 동향\n",
    "2.\t경량 알고리즘\n",
    "  1.\t모델 구조\n",
    "    1.\tResidual Block (Resnet)\n",
    "    2.\tDensely Connected Convolutional Networks (Densenet)\n",
    "    3.\tFire module (Squeezenet)\n",
    "  2.\t합성곱 필터 \n",
    "    1.\tDepthwise Convolution (mobilenet)\n",
    "    2.\tPointwise Convolution\n",
    "    3.\tDepthwise Separable Convolution\n",
    "  3.\t자동 모델 탐색\n",
    "    1.\tNetAdapt\n",
    "    2.\tMNasNet\n",
    "4.\t알고리즘 경량화\n",
    "  5.\t모델 압축\n",
    "    1.\tWeight Pruning\n",
    "    2.\tQuantization & Binarization \n",
    "  6.\t지식 증류\n",
    "    1.\t전문가 모델 – 숙련가 모델 \n",
    "  7.\t하드웨어 가속화\n",
    "    1.\tTPU\n",
    "    2.\tVPU\n",
    "    3.\t젝슨 TX2\n",
    "    4.\t퀄컴 스냅드래곤\n",
    "    5.\tA12 칩\n",
    "    6.\t엑시노스\n",
    "    7.\t등등 NPU \n",
    "  8.\t모델 압축 자동 탐색\n",
    "    1.\tTencent의 PocketFlow\n",
    "    2.\tAutoMC (Automated Model Compression)\t\n",
    "  9.\t실험 \n",
    "    1.\t비교 모델\n",
    "    2.\t개발 환경 및 code 구성\n",
    "    3 .\t성능 비교\n",
    "    4.\tInsight\n",
    "10.\t차주 계획\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNmT48vALjG+hejQmPj4Wuo",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MobileNet_V3_Small_예시.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
