{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yutan0565/colab_git/blob/main/MobileNet_V3_Small_%EC%98%88%EC%8B%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HgXJWEEeK0D"
   },
   "source": [
    "## 기본 모델 형성\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WWaiDdX78kFi"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fO2RGXR2JRxq"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
    "import tensorflow_model_optimization as tfmot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0ptbBJ19JRz_",
    "outputId": "62cd4cdc-a32f-4fea-e0ef-9eeda05daa8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(raw_train_x.shape)\\nprint(raw_test_x.shape)\\nprint(raw_train_y.shape)\\nprint(raw_test_y.shape)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "\"\"\"\n",
    "print(raw_train_x.shape)\n",
    "print(raw_test_x.shape)\n",
    "print(raw_train_y.shape)\n",
    "print(raw_test_y.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "Y3XsyJumvC4Z",
    "outputId": "5eade7af-bca5-49dc-d289-189e276c368f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(train_x.shape)\\nprint(valid_x.shape)\\nprint(test_x.shape)\\nprint(train_y.shape)\\nprint(valid_y.shape)\\nprint(test_y.shape)\\n\\ndef show_sample(i):\\n  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\\n  plt.imshow(raw_train_x[i])\\n  plt.show()\\n\\nfor i in [2, 10, 12, 14]:\\n  show_sample(i)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float을 넣을거면 0~1 사이 값으로 바꿔야함\n",
    "# integer 형태로 넣어보기\n",
    "train_x = raw_train_x[:45000].astype(np.float32)/255.0\n",
    "valid_x = raw_train_x[45000:].astype(np.float32)/255.0\n",
    "test_x = raw_test_x.astype(np.float32)/255.0\n",
    "\n",
    "\n",
    "train_y = raw_train_y[:45000]\n",
    "valid_y = raw_train_y[45000:]\n",
    "test_y = raw_test_y\n",
    "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(train_x.shape)\n",
    "print(valid_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_y.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "def show_sample(i):\n",
    "  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\n",
    "  plt.imshow(raw_train_x[i])\n",
    "  plt.show()\n",
    "\n",
    "for i in [2, 10, 12, 14]:\n",
    "  show_sample(i)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nLvUwGGvQ8w",
    "outputId": "82aa95f2-4a16-49cb-ca7f-798122bc737b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "MobilenetV3small (Functional (None, 1, 1, 1024)        1529968   \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 10)                3159050   \n",
      "=================================================================\n",
      "Total params: 4,689,018\n",
      "Trainable params: 4,676,906\n",
      "Non-trainable params: 12,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile = MobileNetV3Small(  #weights = 'imagenet',  #그냥 초기화 하는거면, 이거 지우기\n",
    "                            include_top = False,\n",
    "                            input_shape=(32,32,3)\n",
    "                            )\n",
    "\n",
    "# vgg conv 구조만 사용하고 마지막 FC layer는 다른거 사용\n",
    "\n",
    "fc_layer = keras.Sequential([\n",
    "                             layers.Flatten(),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(10, activation = \"sigmoid\")\n",
    "                             ])\n",
    "\n",
    "model = keras.Sequential([mobile,\n",
    "                          fc_layer\n",
    "                          ])\n",
    "model.summary()\n",
    "# mobile.summary()\n",
    "# fc_layer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NgPjo_LX7X6x"
   },
   "outputs": [],
   "source": [
    "# Callback 함수 지정 해주기\n",
    "early_stop = EarlyStopping(patience=30) \n",
    "mc = ModelCheckpoint(\"/check_point.h5\", save_best_only=True) \n",
    "reduce_lr  = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                               factor=0.5, \n",
    "                               patience=5\n",
    "                               ) \n",
    "csvlogger = CSVLogger(\"model_log.log\") \n",
    "\n",
    "# tensorboard 관련 \n",
    "def make_Tensorboard_dir(dir_name):\n",
    "  root_logdir = os.path.join(os.curdir, dir_name)\n",
    "  sub_dir_name = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  return os.path.join(root_logdir, sub_dir_name)\n",
    "\n",
    "dir_name = \"Learning_log\"\n",
    "TB_log_dir = make_Tensorboard_dir(dir_name)\n",
    "TensorB = TensorBoard(log_dir = TB_log_dir)\n",
    "\n",
    "\n",
    "#optimizaer  조정 해주기\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZ-LukhIvphi",
    "outputId": "656b43c1-135b-4314-8443-fb5a414d5345",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 65s 43ms/step - loss: 0.9172 - accuracy: 0.6852 - val_loss: 28.4214 - val_accuracy: 0.1068\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 0.9757 - accuracy: 0.6628 - val_loss: 9.7657 - val_accuracy: 0.0754\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 61s 43ms/step - loss: 0.9530 - accuracy: 0.6724 - val_loss: 4.9630 - val_accuracy: 0.0914\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 61s 43ms/step - loss: 0.9506 - accuracy: 0.6736 - val_loss: 4.4446 - val_accuracy: 0.1108\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 61s 43ms/step - loss: 0.9288 - accuracy: 0.6814 - val_loss: 3.4555 - val_accuracy: 0.1066\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 62s 44ms/step - loss: 0.9089 - accuracy: 0.6888 - val_loss: 8.8872 - val_accuracy: 0.1272\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 61s 43ms/step - loss: 0.9008 - accuracy: 0.6885 - val_loss: 4.1607 - val_accuracy: 0.1044\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 62s 44ms/step - loss: 0.9057 - accuracy: 0.6831 - val_loss: 8.9162 - val_accuracy: 0.0812\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 63s 45ms/step - loss: 0.8285 - accuracy: 0.7107 - val_loss: 16.8691 - val_accuracy: 0.0994\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 65s 46ms/step - loss: 0.8094 - accuracy: 0.7194 - val_loss: 12.3503 - val_accuracy: 0.0936\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.6564 - accuracy: 0.7702 - val_loss: 5.2886 - val_accuracy: 0.1204\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.5921 - accuracy: 0.7914 - val_loss: 8.4616 - val_accuracy: 0.1070\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.5459 - accuracy: 0.8067 - val_loss: 24.8939 - val_accuracy: 0.1034\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 60s 42ms/step - loss: 0.5249 - accuracy: 0.8158 - val_loss: 7.2540 - val_accuracy: 0.0822\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 0.4825 - accuracy: 0.8290 - val_loss: 13.3213 - val_accuracy: 0.0980\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 61s 43ms/step - loss: 0.3845 - accuracy: 0.8644 - val_loss: 9.1146 - val_accuracy: 0.1274\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.3407 - accuracy: 0.8795 - val_loss: 8.5701 - val_accuracy: 0.1518\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.3198 - accuracy: 0.8857 - val_loss: 4.2955 - val_accuracy: 0.2162\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.2941 - accuracy: 0.8956 - val_loss: 8.7030 - val_accuracy: 0.1544\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 61s 43ms/step - loss: 0.2801 - accuracy: 0.9004 - val_loss: 7.8747 - val_accuracy: 0.1796\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 61s 43ms/step - loss: 0.2423 - accuracy: 0.9173 - val_loss: 3.4048 - val_accuracy: 0.4100\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 60s 42ms/step - loss: 0.2172 - accuracy: 0.9225 - val_loss: 8.0813 - val_accuracy: 0.1228\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.2020 - accuracy: 0.9285 - val_loss: 8.2489 - val_accuracy: 0.1782\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 60s 42ms/step - loss: 0.1896 - accuracy: 0.9339 - val_loss: 3.3238 - val_accuracy: 0.4356\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 0.1850 - accuracy: 0.9338 - val_loss: 8.7056 - val_accuracy: 0.1862\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.1732 - accuracy: 0.9392 - val_loss: 3.5689 - val_accuracy: 0.4124\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.1775 - accuracy: 0.9385 - val_loss: 4.5663 - val_accuracy: 0.3714\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 61s 43ms/step - loss: 0.1725 - accuracy: 0.9397 - val_loss: 4.7135 - val_accuracy: 0.3140\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.1592 - accuracy: 0.9438 - val_loss: 2.4662 - val_accuracy: 0.5618\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.1564 - accuracy: 0.9460 - val_loss: 11.8819 - val_accuracy: 0.1312\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.1547 - accuracy: 0.9472 - val_loss: 10.8974 - val_accuracy: 0.1302\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.1594 - accuracy: 0.9462 - val_loss: 4.1496 - val_accuracy: 0.3868\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.1568 - accuracy: 0.9459 - val_loss: 3.1865 - val_accuracy: 0.4662\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.1408 - accuracy: 0.9519 - val_loss: 5.5203 - val_accuracy: 0.3120\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.1251 - accuracy: 0.9569 - val_loss: 2.1361 - val_accuracy: 0.6102\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 61s 43ms/step - loss: 0.1152 - accuracy: 0.9606 - val_loss: 3.6772 - val_accuracy: 0.4432\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.1156 - accuracy: 0.9606 - val_loss: 2.5678 - val_accuracy: 0.5544\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.1109 - accuracy: 0.9623 - val_loss: 3.4640 - val_accuracy: 0.4778\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 0.1064 - accuracy: 0.9634 - val_loss: 4.9001 - val_accuracy: 0.3606\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.1087 - accuracy: 0.9626 - val_loss: 2.3153 - val_accuracy: 0.6032\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.1021 - accuracy: 0.9639 - val_loss: 2.0025 - val_accuracy: 0.6444\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 60s 42ms/step - loss: 0.0955 - accuracy: 0.9663 - val_loss: 1.9572 - val_accuracy: 0.6620\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 60s 42ms/step - loss: 0.0986 - accuracy: 0.9661 - val_loss: 2.1344 - val_accuracy: 0.6346\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 0.0951 - accuracy: 0.9676 - val_loss: 2.2112 - val_accuracy: 0.6246\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0962 - accuracy: 0.9670 - val_loss: 2.9502 - val_accuracy: 0.5394\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0958 - accuracy: 0.9673 - val_loss: 1.9372 - val_accuracy: 0.6542\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0900 - accuracy: 0.9700 - val_loss: 1.9131 - val_accuracy: 0.6656\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0889 - accuracy: 0.9701 - val_loss: 2.4507 - val_accuracy: 0.6060\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0873 - accuracy: 0.9703 - val_loss: 3.0456 - val_accuracy: 0.5320\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0892 - accuracy: 0.9705 - val_loss: 4.4131 - val_accuracy: 0.4070\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 61s 43ms/step - loss: 0.0910 - accuracy: 0.9692 - val_loss: 2.2949 - val_accuracy: 0.6110\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0871 - accuracy: 0.9702 - val_loss: 2.5282 - val_accuracy: 0.5986\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0794 - accuracy: 0.9737 - val_loss: 1.8879 - val_accuracy: 0.6732\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0834 - accuracy: 0.9726 - val_loss: 1.9424 - val_accuracy: 0.6652\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0846 - accuracy: 0.9708 - val_loss: 2.0839 - val_accuracy: 0.6492\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0813 - accuracy: 0.9725 - val_loss: 2.7960 - val_accuracy: 0.5758\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0833 - accuracy: 0.9723 - val_loss: 2.4875 - val_accuracy: 0.6016\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0791 - accuracy: 0.9733 - val_loss: 1.9306 - val_accuracy: 0.6726\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0762 - accuracy: 0.9747 - val_loss: 2.3927 - val_accuracy: 0.6164\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 61s 44ms/step - loss: 0.0751 - accuracy: 0.9741 - val_loss: 1.8750 - val_accuracy: 0.6818\n",
      "Epoch 61/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 0.0763 - accuracy: 0.9740 - val_loss: 1.9243 - val_accuracy: 0.6790\n",
      "Epoch 62/100\n",
      "1407/1407 [==============================] - 61s 43ms/step - loss: 0.0756 - accuracy: 0.9746 - val_loss: 1.9491 - val_accuracy: 0.6710\n",
      "Epoch 63/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 0.0757 - accuracy: 0.9751 - val_loss: 2.2213 - val_accuracy: 0.6402\n",
      "Epoch 64/100\n",
      "1407/1407 [==============================] - 61s 43ms/step - loss: 0.0747 - accuracy: 0.9748 - val_loss: 2.0152 - val_accuracy: 0.6638\n",
      "Epoch 65/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0731 - accuracy: 0.9761 - val_loss: 1.9294 - val_accuracy: 0.6738\n",
      "Epoch 66/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0765 - accuracy: 0.9746 - val_loss: 1.9957 - val_accuracy: 0.6682\n",
      "Epoch 67/100\n",
      "1407/1407 [==============================] - 60s 42ms/step - loss: 0.0743 - accuracy: 0.9749 - val_loss: 1.9234 - val_accuracy: 0.6732\n",
      "Epoch 68/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0793 - accuracy: 0.9742 - val_loss: 1.9150 - val_accuracy: 0.6728\n",
      "Epoch 69/100\n",
      "1407/1407 [==============================] - 60s 42ms/step - loss: 0.0726 - accuracy: 0.9742 - val_loss: 1.9036 - val_accuracy: 0.6808\n",
      "Epoch 70/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0734 - accuracy: 0.9754 - val_loss: 2.0043 - val_accuracy: 0.6664\n",
      "Epoch 71/100\n",
      "1407/1407 [==============================] - 60s 42ms/step - loss: 0.0742 - accuracy: 0.9747 - val_loss: 1.9249 - val_accuracy: 0.6786\n",
      "Epoch 72/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0763 - accuracy: 0.9749 - val_loss: 1.9007 - val_accuracy: 0.6820\n",
      "Epoch 73/100\n",
      "1407/1407 [==============================] - 60s 42ms/step - loss: 0.0722 - accuracy: 0.9750 - val_loss: 1.9014 - val_accuracy: 0.6838\n",
      "Epoch 74/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 0.0749 - accuracy: 0.9749 - val_loss: 1.9234 - val_accuracy: 0.6794\n",
      "Epoch 75/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0725 - accuracy: 0.9756 - val_loss: 1.9130 - val_accuracy: 0.6800\n",
      "Epoch 76/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 0.0702 - accuracy: 0.9761 - val_loss: 1.9062 - val_accuracy: 0.6822\n",
      "Epoch 77/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 0.0732 - accuracy: 0.9759 - val_loss: 1.9057 - val_accuracy: 0.6808\n",
      "Epoch 78/100\n",
      "1407/1407 [==============================] - 60s 43ms/step - loss: 0.0710 - accuracy: 0.9756 - val_loss: 1.9114 - val_accuracy: 0.6790\n",
      "Epoch 79/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 0.0693 - accuracy: 0.9774 - val_loss: 1.9086 - val_accuracy: 0.6806\n",
      "Epoch 80/100\n",
      "1407/1407 [==============================] - 60s 42ms/step - loss: 0.0681 - accuracy: 0.9768 - val_loss: 1.9082 - val_accuracy: 0.6814\n",
      "Epoch 81/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 0.0697 - accuracy: 0.9756 - val_loss: 1.9030 - val_accuracy: 0.6832\n",
      "Epoch 82/100\n",
      "1407/1407 [==============================] - 59s 42ms/step - loss: 0.0716 - accuracy: 0.9760 - val_loss: 1.9051 - val_accuracy: 0.6836\n",
      "Epoch 83/100\n",
      "1407/1407 [==============================] - 69s 49ms/step - loss: 0.0732 - accuracy: 0.9764 - val_loss: 1.9014 - val_accuracy: 0.6842\n",
      "Epoch 84/100\n",
      "1407/1407 [==============================] - 66s 47ms/step - loss: 0.0725 - accuracy: 0.9759 - val_loss: 1.9083 - val_accuracy: 0.6802\n",
      "Epoch 85/100\n",
      "1407/1407 [==============================] - 64s 45ms/step - loss: 0.0738 - accuracy: 0.9741 - val_loss: 1.9053 - val_accuracy: 0.6834\n",
      "Epoch 86/100\n",
      "1407/1407 [==============================] - 64s 46ms/step - loss: 0.0682 - accuracy: 0.9767 - val_loss: 1.9104 - val_accuracy: 0.6814\n",
      "Epoch 87/100\n",
      "1407/1407 [==============================] - 64s 45ms/step - loss: 0.0695 - accuracy: 0.9766 - val_loss: 1.9080 - val_accuracy: 0.6814\n",
      "Epoch 88/100\n",
      "1407/1407 [==============================] - 64s 46ms/step - loss: 0.0698 - accuracy: 0.9764 - val_loss: 1.9089 - val_accuracy: 0.6812\n",
      "Epoch 89/100\n",
      "1407/1407 [==============================] - 64s 46ms/step - loss: 0.0682 - accuracy: 0.9764 - val_loss: 1.9075 - val_accuracy: 0.6820\n",
      "Epoch 90/100\n",
      "1407/1407 [==============================] - 65s 46ms/step - loss: 0.0731 - accuracy: 0.9747 - val_loss: 1.9092 - val_accuracy: 0.6822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b64125ff98>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer, loss 함수를 정의하고,  학습 준비를 한다,  metrics 는 어떤 일이 발생하는지 보여줄 것들\n",
    "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "# 한번에 몇개의 데이터 학습하고 가중치 갱신할지 \n",
    "model.fit(train_x, train_y,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          #validation_split = 0.1\n",
    "          validation_data = (valid_x, valid_y),\n",
    "          callbacks = [early_stop, reduce_lr , csvlogger]\n",
    "          )\n",
    "\n",
    "# call back 참고 : https://deep-deep-deep.tistory.com/1 들어가면 여러 옵션들이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIGR4cUIFFFG",
    "outputId": "4e8efb31-7e7e-400c-f85a-67d2b59e3b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 17ms/step - loss: 7.1947 - accuracy: 0.2820\n",
      "loss= 7.194672107696533\n",
      "acc= 0.28200000524520874\n",
      "[1 1 8 ... 3 1 8]\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_x, test_y)\n",
    "print(\"loss=\",loss)\n",
    "print(\"acc=\",acc)\n",
    "\n",
    "y_ = model.predict(test_x)\n",
    "predicted = np.argmax(y_, axis=1)\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "q73p7Ywkzv9i",
    "outputId": "bc0a2976-7118-43f2-992d-192770759025"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/mobile_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/mobile_original_checkpoint\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./saved_model/mobile_original.h5\")\n",
    "model.save(\"./saved_model/mobile_original_checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWaTjCHHeZJJ"
   },
   "source": [
    "## int_8 Quantization 진행\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kR1YvGr6TqB0"
   },
   "outputs": [],
   "source": [
    "# 구조까지 들어가 있는거\n",
    "model = tf.keras.models.load_model('./saved_model/mobile_original_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "K_pCuwiQSAec"
   },
   "outputs": [],
   "source": [
    "# input 에 대해서 변수 설정\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_x).batch(1).take(100):\n",
    "    yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mvxpgAD7SAvS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmpwbmr2psi\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmpwbmr2psi\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n",
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    }
   ],
   "source": [
    "# int 8 로 quantization 진행하기\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uLjaFd7wavtS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmpvqh0dlr_\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmpvqh0dlr_\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "# 그냥 파일 형태만 tflite로 변환 (float 형태임)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8xyG2LcUUJT9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZdR24DrHUfpg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5021280"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 저장 해주는 과정\n",
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"/tmp/mobile_tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the unquantized/float model:\n",
    "tflite_model_file = tflite_models_dir/\"mobile_model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = tflite_models_dir/\"mobiile_model_quant.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAK1WC33UfxT"
   },
   "outputs": [],
   "source": [
    "# tensorlffow lite 모델 실행 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "13myIyvtcyto"
   },
   "outputs": [],
   "source": [
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  global test_x\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = test_x[test_image_index]\n",
    "    test_label = test_y[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Lv1HJGcxcJR9"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(tflite_file, model_type):\n",
    "  global test_x\n",
    "  global test_y\n",
    "\n",
    "  test_image_indices = range(test_x.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_image_indices)\n",
    "\n",
    "  accuracy = (np.sum(test_y.reshape(-1)== predictions) * 100) / len(test_x)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bac0X0MIcJ-y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model accuracy is 28.2000% (Number of test samples=10000)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(tflite_model_file, model_type=\"Float\")\n",
    "evaluate_model(tflite_model_quant_file, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJ8BqBRecLa_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Change this to test a different image\n",
    "test_image_index = 1\n",
    "\n",
    "## Helper function to test the models on one image\n",
    "def test_model(tflite_file, test_image_index, model_type):\n",
    "  global test_labels\n",
    "\n",
    "  predictions = run_tflite_model(tflite_file, [test_image_index])\n",
    "\n",
    "  plt.imshow(test_x[test_image_index])\n",
    "  template = model_type + \" Model \\n True:{true}, Predicted:{predict}\"\n",
    "  _ = plt.title(template.format(true= str(test_y[test_image_index]), predict=str(predictions[0])))\n",
    "  plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgJlkK8kdnKT"
   },
   "outputs": [],
   "source": [
    "test_model(tflite_model_file, test_image_index, model_type=\"Float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWXNXX5ydpG5"
   },
   "outputs": [],
   "source": [
    "test_model(tflite_model_quant_file, test_image_index, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm0ntodhlF8y"
   },
   "source": [
    "## Pruning 진행\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjlumF76nDzo"
   },
   "outputs": [],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_x, test_y, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tESxUKGaf5Q"
   },
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Dense, tfmot.sparsity.keras.PrunableLayer):\n",
    "\n",
    "  def get_prunable_weights(self):\n",
    "    # Prune bias also, though that usually harms model accuracy too much.\n",
    "    return [self.kernel, self.bias]\n",
    "\n",
    "# Use `prune_low_magnitude` to make the `MyDenseLayer` layer train with pruning.\n",
    "model_for_pruning = tf.keras.Sequential([\n",
    "  tfmot.sparsity.keras.prune_low_magnitude(MyDenseLayer(20, input_shape=input_shape)),\n",
    "  tf.keras.layers.Flatten()\n",
    "])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dET8FyEYnZdG"
   },
   "outputs": [],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_x.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4voFQPDRyuWG"
   },
   "outputs": [],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_x, train_,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lzpm4N3DyvEp"
   },
   "outputs": [],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_x, test_y, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_ZkuMoWywo6"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtnCY7h-y0Fd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRZDWu6V4A9w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTuWeu5d4BBs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bF_0FHG4BHX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctE1qnS24BO3"
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "%load_ext tensorboard\n",
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ")\n",
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()\n",
    "\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)\n",
    "\n",
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFMqKHpO4MR3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPny8C6A9oWM5wv/y4HdNQm",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1Et-iwTi6UUUc5F1_JvqO-_LjfL43QBV_",
   "name": "MobileNet_V3_Small_예시.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
