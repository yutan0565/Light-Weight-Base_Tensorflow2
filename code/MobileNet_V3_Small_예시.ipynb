{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yutan0565/colab_git/blob/main/code/MobileNet_V3_Small_%EC%98%88%EC%8B%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTOd0ahJOZsr"
   },
   "source": [
    "##기본 모델 형성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNI1wdG4N7yF",
    "outputId": "2080654c-6979-443e-9516-da8a3f2f40f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |█▍                              | 10 kB 20.4 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 20 kB 22.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 30 kB 27.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 40 kB 16.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 51 kB 14.5 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 61 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 71 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 81 kB 14.0 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 92 kB 15.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 102 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 112 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 122 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 133 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 143 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 153 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 163 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 174 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 184 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 194 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 204 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 215 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 225 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 235 kB 16.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 237 kB 16.3 MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pZRQ2Jc4OCS1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "7R6Yikb4OCuf",
    "outputId": "c2fdef5f-6db2-40a4-c2c4-a76675e44fc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(raw_train_x.shape)\\nprint(raw_test_x.shape)\\nprint(raw_train_y.shape)\\nprint(raw_test_y.shape)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "\"\"\"\n",
    "print(raw_train_x.shape)\n",
    "print(raw_test_x.shape)\n",
    "print(raw_train_y.shape)\n",
    "print(raw_test_y.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "yuQ_qeDSODzw",
    "outputId": "13f56c8b-6d6b-4024-bf7f-68d821b8e578"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(train_x.shape)\\nprint(valid_x.shape)\\nprint(test_x.shape)\\nprint(train_y.shape)\\nprint(valid_y.shape)\\nprint(test_y.shape)\\n\\ndef show_sample(i):\\n  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\\n  plt.imshow(raw_train_x[i])\\n  plt.show()\\n\\nfor i in [2, 10, 12, 14]:\\n  show_sample(i)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float을 넣을거면 0~1 사이 값으로 바꿔야함\n",
    "# integer 형태로 넣어보기\n",
    "train_x = raw_train_x[:45000].astype(np.float32)/255.0\n",
    "valid_x = raw_train_x[45000:].astype(np.float32)/255.0\n",
    "test_x = raw_test_x.astype(np.float32)/255.0\n",
    "\n",
    "\n",
    "train_y = raw_train_y[:45000]\n",
    "valid_y = raw_train_y[45000:]\n",
    "test_y = raw_test_y\n",
    "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(train_x.shape)\n",
    "print(valid_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_y.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "def show_sample(i):\n",
    "  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\n",
    "  plt.imshow(raw_train_x[i])\n",
    "  plt.show()\n",
    "\n",
    "for i in [2, 10, 12, 14]:\n",
    "  show_sample(i)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wwn3NFrmOFeq",
    "outputId": "39e134ed-bbd7-4d3b-84b3-18c23da45a40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "MobilenetV3small (Functional (None, 1, 1, 1024)        1529968   \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 10)                3159050   \n",
      "=================================================================\n",
      "Total params: 4,689,018\n",
      "Trainable params: 4,676,906\n",
      "Non-trainable params: 12,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile = MobileNetV3Small(  #weights = 'imagenet',  #그냥 초기화 하는거면, 이거 지우기\n",
    "                            include_top = False,\n",
    "                            input_shape=(32,32,3)\n",
    "                            )\n",
    "\n",
    "# vgg conv 구조만 사용하고 마지막 FC layer는 다른거 사용\n",
    "\n",
    "fc_layer = keras.Sequential([\n",
    "                             layers.Flatten(),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(1024, activation = 'relu'),\n",
    "                             layers.Dense(10, activation = \"sigmoid\")\n",
    "                             ])\n",
    "\n",
    "model = keras.Sequential([mobile,\n",
    "                          fc_layer\n",
    "                          ])\n",
    "model.summary()\n",
    "# mobile.summary()\n",
    "# fc_layer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VuUFfKa1OIUa"
   },
   "outputs": [],
   "source": [
    "# Callback 함수 지정 해주기\n",
    "early_stop = EarlyStopping(patience=30) \n",
    "mc = ModelCheckpoint(\"./best_model/mobile_original_checkpoint\", \n",
    "                     save_best_only=True,\n",
    "                     monitor = 'val_loss',\n",
    "                     verbose = 1,\n",
    "                     mode = 'min') \n",
    "reduce_lr  = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                               factor=0.5, \n",
    "                               patience=5\n",
    "                               ) \n",
    "# tensorboard 관련 \n",
    "def make_Tensorboard_dir(dir_name):\n",
    "  root_logdir = os.path.join(os.curdir, dir_name)\n",
    "  sub_dir_name = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  return os.path.join(root_logdir, sub_dir_name)\n",
    "\n",
    "dir_name = \"Learning_log\"\n",
    "TB_log_dir = make_Tensorboard_dir(dir_name)\n",
    "TensorB = TensorBoard(log_dir = TB_log_dir)\n",
    "\n",
    "\n",
    "#optimizaer  조정 해주기\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3K9FF5gmOLH6",
    "outputId": "2f7c3f80-6d86-4397-f4c1-d892168f980c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 87s 54ms/step - loss: 2.1178 - accuracy: 0.2220 - val_loss: 2.4044 - val_accuracy: 0.0912\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.40443, saving model to ./best_model\\mobile_original_checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 81s 57ms/step - loss: 1.9463 - accuracy: 0.2879 - val_loss: 2.5025 - val_accuracy: 0.1050\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.40443\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 70s 50ms/step - loss: 1.8506 - accuracy: 0.3263 - val_loss: 2.4991 - val_accuracy: 0.1532\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.40443\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 80s 57ms/step - loss: 1.7866 - accuracy: 0.3490 - val_loss: 2.3028 - val_accuracy: 0.1984\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.40443 to 2.30285, saving model to ./best_model\\mobile_original_checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 70s 50ms/step - loss: 1.7233 - accuracy: 0.3767 - val_loss: 2.0139 - val_accuracy: 0.2602\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.30285 to 2.01393, saving model to ./best_model\\mobile_original_checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 71s 50ms/step - loss: 1.6421 - accuracy: 0.4029 - val_loss: 2.2812 - val_accuracy: 0.1978\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.01393\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 69s 49ms/step - loss: 1.5597 - accuracy: 0.4358 - val_loss: 2.3128 - val_accuracy: 0.1796\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.01393\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 71s 50ms/step - loss: 1.4776 - accuracy: 0.4653 - val_loss: 3.3113 - val_accuracy: 0.0884\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.01393\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 77s 55ms/step - loss: 1.3953 - accuracy: 0.4941 - val_loss: 3.6554 - val_accuracy: 0.0860\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.01393\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 1.3288 - accuracy: 0.5155 - val_loss: 6.7618 - val_accuracy: 0.1154\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.01393\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 1.2472 - accuracy: 0.5442 - val_loss: 3.1372 - val_accuracy: 0.1260\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.01393\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 1.2129 - accuracy: 0.5547 - val_loss: 2.2834 - val_accuracy: 0.2212\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.01393\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 77s 55ms/step - loss: 1.1737 - accuracy: 0.5735 - val_loss: 2.4030 - val_accuracy: 0.2212\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.01393\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 79s 56ms/step - loss: 1.1457 - accuracy: 0.5805 - val_loss: 2.0320 - val_accuracy: 0.3020\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.01393\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 77s 55ms/step - loss: 1.1165 - accuracy: 0.5918 - val_loss: 1.6776 - val_accuracy: 0.4318\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.01393 to 1.67759, saving model to ./best_model\\mobile_original_checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 1.0921 - accuracy: 0.6016 - val_loss: 1.6204 - val_accuracy: 0.4476\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.67759 to 1.62037, saving model to ./best_model\\mobile_original_checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 71s 51ms/step - loss: 1.0545 - accuracy: 0.6155 - val_loss: 1.4082 - val_accuracy: 0.5048\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.62037 to 1.40816, saving model to ./best_model\\mobile_original_checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 69s 49ms/step - loss: 1.0308 - accuracy: 0.6260 - val_loss: 1.5506 - val_accuracy: 0.4622\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.40816\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 70s 50ms/step - loss: 1.0020 - accuracy: 0.6350 - val_loss: 1.9079 - val_accuracy: 0.3548\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.40816\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 75s 54ms/step - loss: 0.9761 - accuracy: 0.6443 - val_loss: 1.9812 - val_accuracy: 0.4056\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.40816\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 71s 50ms/step - loss: 0.9544 - accuracy: 0.6538 - val_loss: 2.0009 - val_accuracy: 0.3954\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.40816\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 69s 49ms/step - loss: 0.9231 - accuracy: 0.6629 - val_loss: 1.7886 - val_accuracy: 0.4398\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.40816\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.8669 - accuracy: 0.6833 - val_loss: 1.7021 - val_accuracy: 0.4650\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.40816\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 98s 70ms/step - loss: 0.8465 - accuracy: 0.6899 - val_loss: 1.5337 - val_accuracy: 0.4956\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.40816\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 77s 54ms/step - loss: 0.8364 - accuracy: 0.6964 - val_loss: 1.7903 - val_accuracy: 0.4526\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.40816\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.8202 - accuracy: 0.7017 - val_loss: 1.5249 - val_accuracy: 0.5094\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.40816\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 80s 57ms/step - loss: 0.7942 - accuracy: 0.7105 - val_loss: 1.5314 - val_accuracy: 0.5216\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.40816\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 87s 62ms/step - loss: 0.7675 - accuracy: 0.7214 - val_loss: 1.7365 - val_accuracy: 0.4670\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.40816\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 100s 71ms/step - loss: 0.7520 - accuracy: 0.7266 - val_loss: 1.5250 - val_accuracy: 0.5220\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.40816\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 144s 102ms/step - loss: 0.7393 - accuracy: 0.7332 - val_loss: 1.5745 - val_accuracy: 0.5228\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.40816\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 116s 82ms/step - loss: 0.7308 - accuracy: 0.7362 - val_loss: 1.4187 - val_accuracy: 0.5512\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.40816\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 81s 57ms/step - loss: 0.7218 - accuracy: 0.7364 - val_loss: 1.5345 - val_accuracy: 0.5314\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.40816\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.7141 - accuracy: 0.7428 - val_loss: 1.3892 - val_accuracy: 0.5626\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.40816 to 1.38922, saving model to ./best_model\\mobile_original_checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model\\mobile_original_checkpoint\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 85s 60ms/step - loss: 0.6979 - accuracy: 0.7468 - val_loss: 1.4169 - val_accuracy: 0.5516\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.38922\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 74s 52ms/step - loss: 0.7018 - accuracy: 0.7454 - val_loss: 1.4249 - val_accuracy: 0.5518\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.38922\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 71s 51ms/step - loss: 0.6851 - accuracy: 0.7521 - val_loss: 1.4224 - val_accuracy: 0.5610\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.38922\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 76s 54ms/step - loss: 0.6888 - accuracy: 0.7491 - val_loss: 1.4091 - val_accuracy: 0.5570\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.38922\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 77s 55ms/step - loss: 0.6857 - accuracy: 0.7507 - val_loss: 1.5234 - val_accuracy: 0.5318\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.38922\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 77s 55ms/step - loss: 0.6772 - accuracy: 0.7557 - val_loss: 1.4098 - val_accuracy: 0.5590\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.38922\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 85s 60ms/step - loss: 0.6777 - accuracy: 0.7549 - val_loss: 1.4249 - val_accuracy: 0.5596\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.38922\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 91s 65ms/step - loss: 0.6657 - accuracy: 0.7598 - val_loss: 1.4223 - val_accuracy: 0.5632\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.38922\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 86s 61ms/step - loss: 0.6649 - accuracy: 0.7576 - val_loss: 1.4372 - val_accuracy: 0.5608\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.38922\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.6678 - accuracy: 0.7589 - val_loss: 1.4310 - val_accuracy: 0.5624\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.38922\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.6552 - accuracy: 0.7633 - val_loss: 1.4243 - val_accuracy: 0.5656\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.38922\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.6570 - accuracy: 0.7620 - val_loss: 1.4210 - val_accuracy: 0.5660\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.38922\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 84s 59ms/step - loss: 0.6562 - accuracy: 0.7619 - val_loss: 1.4265 - val_accuracy: 0.5642\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.38922\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.6645 - accuracy: 0.7598 - val_loss: 1.4243 - val_accuracy: 0.5650\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.38922\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 71s 50ms/step - loss: 0.6623 - accuracy: 0.7602 - val_loss: 1.4379 - val_accuracy: 0.5650\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.38922\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 71s 51ms/step - loss: 0.6569 - accuracy: 0.7624 - val_loss: 1.4260 - val_accuracy: 0.5664\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.38922\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.6518 - accuracy: 0.7647 - val_loss: 1.4317 - val_accuracy: 0.5622\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.38922\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.6565 - accuracy: 0.7636 - val_loss: 1.4339 - val_accuracy: 0.5652\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.38922\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 72s 51ms/step - loss: 0.6485 - accuracy: 0.7653 - val_loss: 1.4361 - val_accuracy: 0.5632\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.38922\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 73s 52ms/step - loss: 0.6447 - accuracy: 0.7669 - val_loss: 1.4315 - val_accuracy: 0.5666\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.38922\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 75s 53ms/step - loss: 0.6465 - accuracy: 0.7676 - val_loss: 1.4311 - val_accuracy: 0.5642\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.38922\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 79s 56ms/step - loss: 0.6526 - accuracy: 0.7644 - val_loss: 1.4328 - val_accuracy: 0.5648\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.38922\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 80s 57ms/step - loss: 0.6530 - accuracy: 0.7633 - val_loss: 1.4334 - val_accuracy: 0.5648\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.38922\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 83s 59ms/step - loss: 0.6498 - accuracy: 0.7659 - val_loss: 1.4328 - val_accuracy: 0.5636\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.38922\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 82s 58ms/step - loss: 0.6455 - accuracy: 0.7673 - val_loss: 1.4336 - val_accuracy: 0.5638\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.38922\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.6457 - accuracy: 0.7661 - val_loss: 1.4341 - val_accuracy: 0.5636\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.38922\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 93s 66ms/step - loss: 0.6487 - accuracy: 0.7684 - val_loss: 1.4338 - val_accuracy: 0.5648\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.38922\n",
      "Epoch 61/100\n",
      "1407/1407 [==============================] - 87s 62ms/step - loss: 0.6480 - accuracy: 0.7654 - val_loss: 1.4341 - val_accuracy: 0.5634\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.38922\n",
      "Epoch 62/100\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 0.6442 - accuracy: 0.7682 - val_loss: 1.4356 - val_accuracy: 0.5644\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.38922\n",
      "Epoch 63/100\n",
      "1407/1407 [==============================] - 74s 53ms/step - loss: 0.6449 - accuracy: 0.7684 - val_loss: 1.4354 - val_accuracy: 0.5636\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.38922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d618e97a58>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer, loss 함수를 정의하고,  학습 준비를 한다,  metrics 는 어떤 일이 발생하는지 보여줄 것들\n",
    "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "# 한번에 몇개의 데이터 학습하고 가중치 갱신할지 \n",
    "model.fit(train_x, train_y,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          #validation_split = 0.1\n",
    "          validation_data = (valid_x, valid_y),\n",
    "          callbacks = [early_stop, reduce_lr , mc]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rxjhscjOR5w",
    "outputId": "597bc3a8-b80a-4e88-de02-dbda97b583bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 20ms/step - loss: 1.4477 - accuracy: 0.5495\n",
      "loss= 1.4477185010910034\n",
      "acc= 0.5494999885559082\n",
      "[3 8 8 ... 5 3 7]\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_x, test_y)\n",
    "print(\"loss=\",loss)\n",
    "print(\"acc=\",acc)\n",
    "\n",
    "y_ = model.predict(test_x)\n",
    "predicted = np.argmax(y_, axis=1)\n",
    "\n",
    "print(predicted)\n",
    "\n",
    "## 75.2\n",
    "## 67.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8AuRmRIqOTXd",
    "outputId": "b1baed42-f47a-4924-ffb7-17d4988046a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/mobile_original_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/mobile_original_checkpoint\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./saved_model/mobile_original.h5\")\n",
    "model.save(\"./saved_model/mobile_original_checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMQkmsTBOdJC"
   },
   "source": [
    "##int_8 Quantization 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8mdt9FmAOUj9"
   },
   "outputs": [],
   "source": [
    "# 구조까지 들어가 있는거\n",
    "model = tf.keras.models.load_model('./best_model/mobile_original_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mnkSbZd_Oc3R"
   },
   "outputs": [],
   "source": [
    "# input 에 대해서 변수 설정\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_x).batch(1).take(100):\n",
    "    yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5NJDbarOlhc",
    "outputId": "335fc300-1d60-42ff-9b1c-eb01e77fd395"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmpjwnj9o02\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmpjwnj9o02\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n",
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    }
   ],
   "source": [
    "# int 8 로 quantization 진행하기\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qIfHHR7QOm60",
    "outputId": "beae9200-3143-4ffb-b74e-86a7405cc20c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmpzrj_kl63\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yutan\\AppData\\Local\\Temp\\tmpzrj_kl63\\assets\n",
      "C:\\Users\\yutan\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "# 그냥 파일 형태만 tflite로 변환 (float 형태임)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ncXY1MmKOobq",
    "outputId": "a4cd7d6d-68ed-4e39-9516-c61287abe357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tZXPnySKOo6w",
    "outputId": "5248bea5-b071-4771-8ed6-47a87d7fb765"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5021280"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 저장 해주는 과정\n",
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"./tflite/mobile_tflite/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the unquantized/float model:\n",
    "tflite_model_file = tflite_models_dir/\"mobile_original_tflite.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = tflite_models_dir/\"mobiile_quantization_tflite.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Su6SO1CKOqLi"
   },
   "outputs": [],
   "source": [
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  global test_x\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = test_x[test_image_index]\n",
    "    test_label = test_y[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LqT2rNGPOrh5"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(tflite_file, model_type):\n",
    "  global test_x\n",
    "  global test_y\n",
    "\n",
    "  test_image_indices = range(test_x.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_image_indices)\n",
    "\n",
    "  accuracy = (np.sum(test_y.reshape(-1)== predictions) * 100) / len(test_x)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CPgDYzNWcnM",
    "outputId": "58fb64a3-7b2c-4c65-ab57-80db86dae74a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model accuracy is 54.9700% (Number of test samples=10000)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(tflite_model_file, model_type=\"Float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10740/3649916578.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_model_quant_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Quantized\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10740/2827655062.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(tflite_file, model_type)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mtest_image_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m   \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_tflite_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_image_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10740/2871110346.py\u001b[0m in \u001b[0;36mrun_tflite_model\u001b[1;34m(tflite_file, test_image_indices)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_details\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_details\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"index\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_details\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"index\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36minvoke\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    873\u001b[0m     \"\"\"\n\u001b[0;32m    874\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_safe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_all_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate_model(tflite_model_quant_file, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tflite_time(tflite_file, test_image_indices):\n",
    "  global test_x\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = test_x[test_image_index]\n",
    "    test_label = test_y[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "        \n",
    "    start = time.time()\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    end = time.time()\n",
    "    \n",
    "    fps = 1 / (end - start)\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYzMVTwNOsi7"
   },
   "outputs": [],
   "source": [
    "# Change this to test a different image\n",
    "test_image_index = 1\n",
    "\n",
    "def test_model_time(tflite_file, test_image_index, model_type):\n",
    "  global test_y\n",
    "  fps = run_tflite_time(tflite_file, [test_image_index])\n",
    "  print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_wYKm4jOtj4"
   },
   "outputs": [],
   "source": [
    "test_model_time(tflite_model_file, test_image_index, model_type=\"Float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ti97vld-Oume"
   },
   "outputs": [],
   "source": [
    "test_model_time(tflite_model_quant_file, test_image_index, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q85dwKpQOwv1"
   },
   "source": [
    "##Pruning 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9SM32mkOvoT"
   },
   "outputs": [],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_x, test_y, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubhlv_QcOzEJ"
   },
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Dense, tfmot.sparsity.keras.PrunableLayer):\n",
    "\n",
    "  def get_prunable_weights(self):\n",
    "    # Prune bias also, though that usually harms model accuracy too much.\n",
    "    return [self.kernel, self.bias]\n",
    "\n",
    "# Use `prune_low_magnitude` to make the `MyDenseLayer` layer train with pruning.\n",
    "model_for_pruning = tf.keras.Sequential([\n",
    "  tfmot.sparsity.keras.prune_low_magnitude(MyDenseLayer(20, input_shape=input_shape)),\n",
    "  tf.keras.layers.Flatten()\n",
    "])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xh6Y4z3sO0AI"
   },
   "outputs": [],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_x.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGqo2IrqO0__"
   },
   "outputs": [],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_x, train_,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1PONfqRO165"
   },
   "outputs": [],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_x, test_y, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ur8LuxUO3ht"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ke3yltbMO4hd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNmT48vALjG+hejQmPj4Wuo",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MobileNet_V3_Small_예시.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
