{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_week_test",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrc5wtnbnqfcLB1FA4Am/u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yutan0565/colab_git/blob/main/2_week_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SFkc5ZsoJULI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import EfficientNetB0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(weights = 'imagenet')\n",
        "resnet = ResNet50(weights = 'imagenet')\n",
        "efficientnet = EfficientNetB0(weights = 'imagenet')"
      ],
      "metadata": {
        "id": "Wmw_5eltJqMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vgg.summary())\n",
        "\"\"\"\n",
        " [(None, 224, 224, 3)]\n",
        " Total params: 138,357,544\n",
        "Trainable params: 138,357,544\n",
        "Non-trainable params: 0\n",
        "\"\"\"\n",
        "print(resnet.summary())\n",
        "\"\"\"\n",
        "[(None, 224, 224, 3  0)]\n",
        "Total params: 25,636,712\n",
        "Trainable params: 25,583,592\n",
        "Non-trainable params: 53,120\n",
        "\"\"\"\n",
        "print(efficientnet.summary())\n",
        "\"\"\"\n",
        "[(None, 224, 224, 3  0)]\n",
        "Total params: 5,330,571\n",
        "Trainable params: 5,288,548\n",
        "Non-trainable params: 42,023\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vd6brA4MJzXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0mAL9QXjh8f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Denselayer 부분만 양자화 해주기\n",
        "!pip install tensorflow_model_optimization\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "def apply_quantization_to_dense(layer):\n",
        "  if isinstance(layer, tf.keras.layers.Dense):\n",
        "    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "  return layer\n",
        "\n",
        "annotated_model = tf.keras.models.clone_model(\n",
        "    vgg,\n",
        "    clone_function=apply_quantization_to_dense,\n",
        ")\n",
        "\n",
        "quant_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
        "quant_aware_model.summary()\n"
      ],
      "metadata": {
        "id": "5d1tgru9KFDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 양자화 해주기\n",
        "quant_aware_model_all = tfmot.quantization.keras.quantize_model(vgg)\n",
        "quant_aware_model_all.summary()"
      ],
      "metadata": {
        "id": "-TPZT-hkLc2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!mkdir tiny_imagenet"
      ],
      "metadata": {
        "id": "CkhoWdG7MlrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "src_path = \"./tiny_imagenet/\"\n",
        "train_dst_path = \"./train/\"\n",
        "test_dst_path = \"./test/\"\n",
        "split_ratio = 0.9\n",
        "\n",
        "\n",
        "\n",
        "def check_folder_and_make(path):\n",
        "    if not os.path.isdir(path):\n",
        "        os.mkdir(path)\n",
        "\n",
        "def main():\n",
        "    check_folder_and_make(train_dst_path)\n",
        "    check_folder_and_make(test_dst_path)\n",
        "    folders = os.listdir(src_path)\n",
        "    for folder in folders:\n",
        "        check_folder_and_make(train_dst_path+folder)\n",
        "        check_folder_and_make(test_dst_path+folder)\n",
        "        img_paths = glob.glob(src_path+folder+\"/images/*.JPEG\")\n",
        "\n",
        "        img_len = len(img_paths)\n",
        "        train_index = int(img_len * split_ratio)\n",
        "\n",
        "        train_set = img_paths[:train_index]\n",
        "        test_set = img_paths[train_index:]\n",
        "\n",
        "        for train in train_set:\n",
        "            shutil.copy2(train, train_dst_path+folder)\n",
        "\n",
        "        for test in test_set:\n",
        "            shutil.copy2(test, test_dst_path+folder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "xyg9ojU5fjo3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    im = cv2.resize(cv2.imread('cat.jpg'), (224, 224)).astype(np.float32)\n",
        "    im[:,:,0] -= 103.939\n",
        "    im[:,:,1] -= 116.779\n",
        "    im[:,:,2] -= 123.68\n",
        "    im = im.transpose((2,0,1))\n",
        "    im = np.expand_dims(im, axis=0)\n",
        "\n",
        "    # Test pretrained model\n",
        "    model = VGG_16('vgg16_weights.h5')\n",
        "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
        "    out = model.predict(im)\n",
        "    print np.argmax(out)"
      ],
      "metadata": {
        "id": "VyVkGysYiYOi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}