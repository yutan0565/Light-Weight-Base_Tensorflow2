{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNet_V3_Small_예시.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Et-iwTi6UUUc5F1_JvqO-_LjfL43QBV_",
      "authorship_tag": "ABX9TyPPk0BFVvkQfhPcnGKDkNbw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yutan0565/colab_git/blob/main/MobileNet_V3_Small_%EC%98%88%EC%8B%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pathlib\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "\n"
      ],
      "metadata": {
        "id": "fO2RGXR2JRxq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "\"\"\"\n",
        "print(raw_train_x.shape)\n",
        "print(raw_test_x.shape)\n",
        "print(raw_train_y.shape)\n",
        "print(raw_test_y.shape)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0ptbBJ19JRz_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# float을 넣을거면 0~1 사이 값으로 바꿔야함\n",
        "train_x = raw_train_x[:45000].astype(np.float32)/255.0\n",
        "valid_x = raw_train_x[45000:].astype(np.float32)/255.0\n",
        "test_x = raw_test_x.astype(np.float32)/255.0\n",
        "\n",
        "\n",
        "train_y = raw_train_y[:45000]\n",
        "valid_y = raw_train_y[45000:]\n",
        "test_y = raw_test_y\n",
        "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "print(train_x.shape)\n",
        "print(valid_x.shape)\n",
        "print(test_x.shape)\n",
        "print(train_y.shape)\n",
        "print(valid_y.shape)\n",
        "print(test_y.shape)\n",
        "\n",
        "def show_sample(i):\n",
        "  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\n",
        "  plt.imshow(raw_train_x[i])\n",
        "  plt.show()\n",
        "\n",
        "for i in [2, 10, 12, 14]:\n",
        "  show_sample(i)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Y3XsyJumvC4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "a82857ce-396d-49c8-eed8-cd6f18eca997"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45000, 32, 32, 3)\n",
            "(5000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(45000, 1)\n",
            "(5000, 1)\n",
            "(10000, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef show_sample(i):\\n  print(raw_train_y[i][0], labels[raw_train_y[i][0]])\\n  plt.imshow(raw_train_x[i])\\n  plt.show()\\n\\nfor i in [2, 10, 12, 14]:\\n  show_sample(i)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobile = MobileNetV3Small(             # weights = 'imagenet',  그냥 초기화 하는거면, 이거 지우기\n",
        "                            include_top = False,\n",
        "                            input_shape=(32,32,3)\n",
        "                            )\n",
        "\n",
        "# vgg conv 구조만 사용하고 마지막 FC layer는 다른거 사용\n",
        "\n",
        "fc_layer = keras.Sequential([\n",
        "                             layers.Flatten(),\n",
        "                             layers.Dense(512, activation = 'relu'),\n",
        "                             layers.Dense(512, activation = 'relu'),\n",
        "                             layers.Dense(10, activation = \"sigmoid\")\n",
        "                             ])\n",
        "\n",
        "model = keras.Sequential([mobile,\n",
        "                          fc_layer\n",
        "                          ])\n",
        "\n",
        "# mobile.summary()\n",
        "# fc_layer.summary()\n"
      ],
      "metadata": {
        "id": "1nLvUwGGvQ8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(patience=20) \n",
        "mc = ModelCheckpoint(\"/check_point.h5\", save_best_only=True) \n",
        "reduce_lr  = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                               factor=0.1, \n",
        "                               patience=5\n",
        "                               ) \n",
        "csvlogger = CSVLogger(\"model_log.log\") \n",
        "\n",
        "\n",
        "# optimizer, loss 함수를 정의하고,  학습 준비를 한다,  metrics 는 어떤 일이 발생하는지 보여줄 것들\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "\n",
        "# 한번에 몇개의 데이터 학습하고 가중치 갱신할지 \n",
        "model.fit(train_x, train_y,\n",
        "          epochs=1,\n",
        "          verbose=1,\n",
        "          batch_size=128,\n",
        "          #validation_split = 0.1\n",
        "          validation_data = (valid_x, valid_y),\n",
        "          callbacks = [es, mc, reduce_lr , csvlogger]\n",
        "          )\n",
        "\n",
        "# call back 참고 : https://deep-deep-deep.tistory.com/1 들어가면 여러 옵션들이 나옴"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ-LukhIvphi",
        "outputId": "45477609-cbea-4a03-d7da-851530b3307d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "352/352 [==============================] - 80s 212ms/step - loss: 1.8539 - accuracy: 0.3281 - val_loss: 2.4161 - val_accuracy: 0.0950 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f79c7ee7cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)"
      ],
      "metadata": {
        "id": "sIGR4cUIFFFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce52c139-b861-4db2-f251-1f1a91ba0cf2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 6s 18ms/step - loss: 2.4121 - accuracy: 0.1000\n",
            "loss= 2.4120535850524902\n",
            "acc= 0.10000000149011612\n",
            "[4 4 4 ... 4 4 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 저장하는 2가지 방식\n",
        "#model.save('mobile_h5_model.h5')\n",
        "model.save('saved_model/mobile_model')"
      ],
      "metadata": {
        "id": "56tzoizBvvXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ae145a-e9e0-41a8-9ef9-c0ddb1517152"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/mobile_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/mobile_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구조까지 들어가 있는거\n",
        "#model_load = tf.keras.models.load_model('saved_model/my_model')"
      ],
      "metadata": {
        "id": "kR1YvGr6TqB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input 에 대해서 변수 설정\n",
        "def representative_data_gen():\n",
        "  for input_value in tf.data.Dataset.from_tensor_slices(train_x).batch(1).take(100):\n",
        "    integer_8_image = np.array(input_value, dtype=np.float32)\n",
        "    yield [integer_8_image]"
      ],
      "metadata": {
        "id": "K_pCuwiQSAec"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# int 8 로 quantization 진행하기\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "# Ensure that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "tflite_model_quant = converter.convert()"
      ],
      "metadata": {
        "id": "mvxpgAD7SAvS",
        "outputId": "7d981156-bca2-4c3e-e895-3fb58eca8980",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpxo41f6ew/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpxo41f6ew/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 그냥 파일 형태만 tflite로 변환 (float 형태임)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "id": "uLjaFd7wavtS",
        "outputId": "30281f98-b691-4645-df2a-e6b45233b4d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) MobilenetV3small_input with unsupported characters which will be renamed to mobilenetv3small_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpj_9wxcy8/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpj_9wxcy8/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)"
      ],
      "metadata": {
        "id": "8xyG2LcUUJT9",
        "outputId": "3994b193-1c71-4508-c425-93c9ce51aa8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  <class 'numpy.uint8'>\n",
            "output:  <class 'numpy.uint8'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장 해주는 과정\n",
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"/tmp/mobile_tflite_models/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir/\"mobile_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir/\"mobiile_model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_model_quant)"
      ],
      "metadata": {
        "id": "ZdR24DrHUfpg",
        "outputId": "3401e241-add5-4f5b-b807-c5e60edab2d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1795944"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorlffow lite 모델 실행 해보기"
      ],
      "metadata": {
        "id": "sAK1WC33UfxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_tflite_model(tflite_file, test_image_indices):\n",
        "  global test_x\n",
        "\n",
        "  # Initialize the interpreter\n",
        "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
        "  for i, test_image_index in enumerate(test_image_indices):\n",
        "    test_image = test_x[test_image_index]\n",
        "    test_label = test_y[test_image_index]\n",
        "\n",
        "    # Check if the input type is quantized, then rescale input data to uint8\n",
        "    if input_details['dtype'] == np.uint8:\n",
        "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "      test_image = test_image / input_scale + input_zero_point\n",
        "\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
        "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "    predictions[i] = output.argmax()\n",
        "\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "13myIyvtcyto"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(tflite_file, model_type):\n",
        "  global test_x\n",
        "  global test_y\n",
        "\n",
        "  test_image_indices = range(test_x.shape[0])\n",
        "  predictions = run_tflite_model(tflite_file, test_image_indices)\n",
        "\n",
        "  accuracy = (np.sum(test_y== predictions) * 100) / len(test_x)\n",
        "\n",
        "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
        "      model_type, accuracy, len(test_x)))"
      ],
      "metadata": {
        "id": "Lv1HJGcxcJR9"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(tflite_model_file, model_type=\"Float\")\n",
        "evaluate_model(tflite_model_quant_file, model_type=\"Quantized\")"
      ],
      "metadata": {
        "id": "bac0X0MIcJ-y",
        "outputId": "47d7bf21-6a18-4611-cb5a-1fe4e6ad612d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized model accuracy is 100000.0000% (Number of test samples=10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wJ8BqBRecLa_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}